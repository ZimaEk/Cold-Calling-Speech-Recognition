{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4OmrK76-8od"
      },
      "source": [
        "# Модель расшифрофки Whisper + Diarisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "j6X8LqqHQ-Uv",
        "outputId": "52245c3f-8b38-46b5-be3d-c1da3e4109d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-m0y1lorm\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-m0y1lorm\n",
            "  Resolved https://github.com/openai/whisper.git to commit 517a43ecd132a2089d85f4ebc044728a71d49f6e\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (10.6.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (0.9.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (3.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper==20240930) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20240930) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper==20240930) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper==20240930) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "# загрузить последний коммит Whisper с зависимостями\n",
        "\n",
        "!pip install git+https://github.com/openai/whisper.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "9BUTTHDhQ89Q",
        "outputId": "fba916a5-20d7-4fde-df4f-2898e1fa669a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyannote.audio\n",
            "  Downloading pyannote.audio-3.3.2-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting asteroid-filterbanks>=0.4 (from pyannote.audio)\n",
            "  Downloading asteroid_filterbanks-0.4.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (0.8.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (0.30.2)\n",
            "Collecting lightning>=2.0.1 (from pyannote.audio)\n",
            "  Downloading lightning-2.5.1-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting omegaconf<3.0,>=2.1 (from pyannote.audio)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting pyannote.core>=5.0.0 (from pyannote.audio)\n",
            "  Downloading pyannote.core-5.0.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting pyannote.database>=5.0.1 (from pyannote.audio)\n",
            "  Downloading pyannote.database-5.1.3-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pyannote.metrics>=3.2 (from pyannote.audio)\n",
            "  Downloading pyannote.metrics-3.2.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting pyannote.pipeline>=3.0.1 (from pyannote.audio)\n",
            "  Downloading pyannote.pipeline-3.0.1-py3-none-any.whl.metadata (897 bytes)\n",
            "Collecting pytorch-metric-learning>=2.1.0 (from pyannote.audio)\n",
            "  Downloading pytorch_metric_learning-2.8.1-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (13.9.4)\n",
            "Collecting semver>=3.0.0 (from pyannote.audio)\n",
            "  Downloading semver-3.0.4-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (0.13.1)\n",
            "Collecting speechbrain>=1.0.0 (from pyannote.audio)\n",
            "  Downloading speechbrain-1.0.3-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting tensorboardX>=2.6 (from pyannote.audio)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (2.6.0+cu124)\n",
            "Collecting torch-audiomentations>=0.11.0 (from pyannote.audio)\n",
            "  Downloading torch_audiomentations-0.12.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: torchaudio>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (2.6.0+cu124)\n",
            "Collecting torchmetrics>=0.11.0 (from pyannote.audio)\n",
            "  Downloading torchmetrics-1.7.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from asteroid-filterbanks>=0.4->pyannote.audio) (2.0.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from asteroid-filterbanks>=0.4->pyannote.audio) (4.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (4.67.1)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning>=2.0.1->pyannote.audio)\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting pytorch-lightning (from lightning>=2.0.1->pyannote.audio)\n",
            "  Downloading pytorch_lightning-2.5.1-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf<3.0,>=2.1->pyannote.audio)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: sortedcontainers>=2.0.4 in /usr/local/lib/python3.11/dist-packages (from pyannote.core>=5.0.0->pyannote.audio) (2.4.0)\n",
            "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.core>=5.0.0->pyannote.audio) (1.14.1)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.11/dist-packages (from pyannote.database>=5.0.1->pyannote.audio) (2.2.2)\n",
            "Requirement already satisfied: typer>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.database>=5.0.1->pyannote.audio) (0.15.2)\n",
            "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (1.6.1)\n",
            "Collecting docopt>=0.6.2 (from pyannote.metrics>=3.2->pyannote.audio)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (0.9.0)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (3.10.0)\n",
            "Requirement already satisfied: sympy>=1.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (1.13.1)\n",
            "Collecting optuna>=3.1 (from pyannote.pipeline>=3.0.1->pyannote.audio)\n",
            "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.0.0->pyannote.audio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.0.0->pyannote.audio) (2.18.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->pyannote.audio) (1.17.1)\n",
            "Collecting hyperpyyaml (from speechbrain>=1.0.0->pyannote.audio)\n",
            "  Downloading HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from speechbrain>=1.0.0->pyannote.audio) (1.4.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from speechbrain>=1.0.0->pyannote.audio) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX>=2.6->pyannote.audio) (5.29.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (3.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.1->pyannote.metrics>=3.2->pyannote.audio) (1.3.0)\n",
            "Collecting julius<0.3,>=0.2.3 (from torch-audiomentations>=0.11.0->pyannote.audio)\n",
            "  Downloading julius-0.2.7.tar.gz (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-pitch-shift>=1.2.2 (from torch-audiomentations>=0.11.0->pyannote.audio)\n",
            "  Downloading torch_pitch_shift-1.2.5-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->pyannote.audio) (2.22)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (3.11.15)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning>=2.0.1->pyannote.audio) (75.2.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->pyannote.audio) (0.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (2.8.2)\n",
            "Collecting alembic>=1.5.0 (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio)\n",
            "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (2.0.40)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.17.1->pyannote.metrics>=3.2->pyannote.audio) (3.6.0)\n",
            "Collecting primePy>=1.3 (from torch-pitch-shift>=1.2.2->torch-audiomentations>=0.11.0->pyannote.audio)\n",
            "  Downloading primePy-1.3-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio) (1.5.4)\n",
            "Collecting ruamel.yaml>=0.17.28 (from hyperpyyaml->speechbrain>=1.0.0->pyannote.audio)\n",
            "  Downloading ruamel.yaml-0.18.10-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->pyannote.audio) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (2025.1.31)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.19.0)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (1.1.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.17.0)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=1.0.0->pyannote.audio)\n",
            "  Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (3.2.0)\n",
            "Downloading pyannote.audio-3.3.2-py2.py3-none-any.whl (898 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m898.7/898.7 kB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asteroid_filterbanks-0.4.0-py3-none-any.whl (29 kB)\n",
            "Downloading lightning-2.5.1-py3-none-any.whl (818 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m818.9/818.9 kB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyannote.core-5.0.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyannote.database-5.1.3-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyannote.metrics-3.2.1-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyannote.pipeline-3.0.1-py3-none-any.whl (31 kB)\n",
            "Downloading pytorch_metric_learning-2.8.1-py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.9/125.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semver-3.0.4-py3-none-any.whl (17 kB)\n",
            "Downloading speechbrain-1.0.3-py3-none-any.whl (864 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m864.1/864.1 kB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_audiomentations-0.12.0-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.7.1-py3-none-any.whl (961 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_pitch_shift-1.2.5-py3-none-any.whl (5.0 kB)\n",
            "Downloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n",
            "Downloading pytorch_lightning-2.5.1-py3-none-any.whl (822 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.0/823.0 kB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading primePy-1.3-py3-none-any.whl (4.0 kB)\n",
            "Downloading ruamel.yaml-0.18.10-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (739 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: antlr4-python3-runtime, docopt, julius\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=9b3e4dec97ad96fe9a69bf21a14879666150d1a9427f0cb179895f1d291d3080\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=49a2f62437a7b1f0fffda2c54661668b62a76663682575253d8c6595efb11c91\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
            "  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for julius: filename=julius-0.2.7-py3-none-any.whl size=21870 sha256=a6b4ecae430431e5519e620f4fe6a927c5109b20a8fbc077746dc5d4ba748e63\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/15/d4/edd724cefe78050a6ba3344b8b0c6672db829a799dbb9f81ff\n",
            "Successfully built antlr4-python3-runtime docopt julius\n",
            "Installing collected packages: primePy, docopt, antlr4-python3-runtime, tensorboardX, semver, ruamel.yaml.clib, omegaconf, lightning-utilities, colorlog, ruamel.yaml, pyannote.core, alembic, optuna, hyperpyyaml, torchmetrics, pytorch-metric-learning, pyannote.database, julius, asteroid-filterbanks, torch-pitch-shift, speechbrain, pytorch-lightning, pyannote.pipeline, pyannote.metrics, torch-audiomentations, lightning, pyannote.audio\n",
            "Successfully installed alembic-1.15.2 antlr4-python3-runtime-4.9.3 asteroid-filterbanks-0.4.0 colorlog-6.9.0 docopt-0.6.2 hyperpyyaml-1.2.2 julius-0.2.7 lightning-2.5.1 lightning-utilities-0.14.3 omegaconf-2.3.0 optuna-4.3.0 primePy-1.3 pyannote.audio-3.3.2 pyannote.core-5.0.0 pyannote.database-5.1.3 pyannote.metrics-3.2.1 pyannote.pipeline-3.0.1 pytorch-lightning-2.5.1 pytorch-metric-learning-2.8.1 ruamel.yaml-0.18.10 ruamel.yaml.clib-0.2.12 semver-3.0.4 speechbrain-1.0.3 tensorboardX-2.6.2.2 torch-audiomentations-0.12.0 torch-pitch-shift-1.2.5 torchmetrics-1.7.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "7bf6209027d343f094cc520659a9cad2",
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install pyannote.audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqCt86n6RdSv"
      },
      "outputs": [],
      "source": [
        "import torchaudio\n",
        "\n",
        "# Конвертация MP3 в WAV\n",
        "waveform, sample_rate = torchaudio.load(\"audio_8.mp3\")\n",
        "torchaudio.save(\"audio_8.wav\", waveform, sample_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bGHSuGhb-_if",
        "outputId": "16e3c67f-94ee-4196-cf14-ba0d45c753bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (0.25.1)\n"
          ]
        }
      ],
      "source": [
        "import whisper\n",
        "from pyannote.audio import Pipeline\n",
        "import torch\n",
        "!pip install pydub\n",
        "import pydub\n",
        "from pydub import AudioSegment\n",
        "from typing import List, Dict, Tuple\n",
        "import numpy as np\n",
        "#!pip install faster-whisper\n",
        "#from faster_whisper import WhisperModel\n",
        "\n",
        "class SpeechDiarizer:\n",
        "    def __init__(self, whisper_model: str = \"medium\", hf_token: str = None):\n",
        "        \"\"\"\n",
        "        Инициализация моделей для транскрибации и диаризации\n",
        "\n",
        "        :param whisper_model: Модель Whisper (tiny, base, small, medium, large)\n",
        "        :param hf_token: Токен для Hugging Face (необходим для pyannote.audio)\n",
        "        \"\"\"\n",
        "        # Загрузка модели Whisper\n",
        "        self.whisper_model = whisper.load_model(whisper_model)\n",
        "\n",
        "        # Загрузка модели диаризации (требуется токен Hugging Face)\n",
        "        if hf_token is None:\n",
        "            raise ValueError(\"Необходим токен Hugging Face для использования pyannote.audio\")\n",
        "\n",
        "        self.diarization_pipeline = Pipeline.from_pretrained(\n",
        "            \"pyannote/speaker-diarization-3.1\",\n",
        "            use_auth_token=hf_token\n",
        "        ).to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
        "\n",
        "    def transcribe_and_diarize(self, audio_path: str) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Транскрибирует аудио и выполняет диаризацию\n",
        "\n",
        "        :param audio_path: Путь к аудиофайлу\n",
        "        :return: Список сегментов с текстом и меткой диктора\n",
        "        \"\"\"\n",
        "        # 1. Транскрибация с Whisper\n",
        "        result = self.whisper_model.transcribe(audio_path)\n",
        "        segments = result[\"segments\"]\n",
        "\n",
        "        # 2. Диаризация с pyannote.audio\n",
        "        diarization = self.diarization_pipeline(audio_path)\n",
        "\n",
        "        # 3. Сопоставление сегментов транскрибации с диаризацией\n",
        "        aligned_segments = self._align_segments(segments, diarization)\n",
        "\n",
        "        return aligned_segments\n",
        "\n",
        "    def _align_segments(self,\n",
        "                       whisper_segments: List[Dict],\n",
        "                       diarization) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Сопоставляет сегменты транскрибации с результатами диаризации\n",
        "\n",
        "        :param whisper_segments: Сегменты из Whisper\n",
        "        :param diarization: Результат диаризации\n",
        "        :return: Объединенные сегменты с информацией о дикторе\n",
        "        \"\"\"\n",
        "        aligned = []\n",
        "\n",
        "        # Преобразуем диаризацию в список для удобства\n",
        "        diarization_segments = []\n",
        "        for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
        "            diarization_segments.append({\n",
        "                \"start\": turn.start,\n",
        "                \"end\": turn.end,\n",
        "                \"speaker\": speaker\n",
        "            })\n",
        "\n",
        "        # Для каждого сегмента Whisper находим соответствующего диктора\n",
        "        for ws in whisper_segments:\n",
        "            ws_start = ws[\"start\"]\n",
        "            ws_end = ws[\"end\"]\n",
        "\n",
        "            # Находим все сегменты диаризации, которые пересекаются с текущим сегментом Whisper\n",
        "            overlapping_speakers = []\n",
        "            for ds in diarization_segments:\n",
        "                if not (ds[\"end\"] < ws_start or ds[\"start\"] > ws_end):\n",
        "                    # Рассчитываем продолжительность пересечения\n",
        "                    overlap_start = max(ws_start, ds[\"start\"])\n",
        "                    overlap_end = min(ws_end, ds[\"end\"])\n",
        "                    overlap_duration = overlap_end - overlap_start\n",
        "\n",
        "                    overlapping_speakers.append({\n",
        "                        \"speaker\": ds[\"speaker\"],\n",
        "                        \"duration\": overlap_duration\n",
        "                    })\n",
        "\n",
        "            # Определяем основного диктора для сегмента\n",
        "            if overlapping_speakers:\n",
        "                # Выбираем диктора с наибольшим временем пересечения\n",
        "                main_speaker = max(overlapping_speakers, key=lambda x: x[\"duration\"])[\"speaker\"]\n",
        "            else:\n",
        "                main_speaker = \"UNKNOWN\"\n",
        "\n",
        "            aligned.append({\n",
        "                \"start\": ws_start,\n",
        "                \"end\": ws_end,\n",
        "                \"text\": ws[\"text\"],\n",
        "                \"speaker\": main_speaker\n",
        "            })\n",
        "\n",
        "        return aligned\n",
        "\n",
        "    def format_output(self, segments: List[Dict]) -> str:\n",
        "        \"\"\"\n",
        "        Форматирует результат в читаемый текст с разметкой дикторов\n",
        "\n",
        "        :param segments: Сегменты с информацией о дикторах\n",
        "        :return: Отформатированная строка\n",
        "        \"\"\"\n",
        "        output = []\n",
        "        current_speaker = None\n",
        "\n",
        "        for seg in segments:\n",
        "            if seg[\"speaker\"] != current_speaker:\n",
        "                output.append(f\"\\n[{seg['speaker']}]\")\n",
        "                current_speaker = seg[\"speaker\"]\n",
        "            output.append(seg[\"text\"])\n",
        "\n",
        "        return \" \".join(output).strip()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEmdK5AD1h5I",
        "outputId": "e6085a46-d3d7-4651-d770-9667268228dc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.11/dist-packages/pyannote/audio/models/blocks/pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)\n",
            "  std = sequences.std(dim=-1, correction=1)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[SPEAKER_00]  Здравствуйте.  Добрый день. Меня зовут Надежда, компания «Апп».  Соедините меня с генеральным директором.  В каком вопросе?  Я звоню по вопросу Шелкотрафарет на печати.  Мне нужно обсудить несколько вопросов с руководителем.  Соедините, пожалуйста.  Ну, вы можете прислать свое коммерческое предложение нам на электронку.  А как вас зовут, скажите, пожалуйста.  Меня зовут Екатерина. Я обязательно доведу до соединения директора.  Екатерина, мы не делаем верно.  Рассылка у нас с сервизной компанией с минимальной репутацией.  Чтобы предложить вам наши услуги,  нужно сначала переговорить с вашим руководителем.  Ну, вы со мной можете переговорить,  потому что я занимаюсь работой с поставщиками.  Меня зовут Екатерина. Пожалуйста.  Екатерина, как правильно называется ваша должность? \n",
            "[UNKNOWN]  Менеджер. \n",
            "[SPEAKER_00]  Екатерина, мы предлагаем вам Шелкотрафарет на печати,  флаками, красками на бумаге, пластике, картоне  и других материалов для производства печатной  продукции, постматериалов и многого другого.  Мы бесплатно напечатаем вам пилотные образцы,  бесплатно заберем и доставим заказ.  И сделаем всего за 12 часов даже большей тирже в десяткой тысячи листов.  Плюс до конца недели вы получаете скидку 15% на первые месяцы сотрудничества.  Поэтому я предлагаю встретиться с ведущим специалистом по нашим услугам.  Он подробно расскажет, что может быть возможным.  Знаете, у нас маленькая компания, поэтому вот с поставщиками работаю я.  Поэтому если хотите встретиться, пожалуйста, приезжайте.  Мы пообщаемся.  А еще я хотела уточнить, а вы где находитесь территориально?  У вас офис, производ?  В нашей компании находится по адресу Московской области город Королев.  А в Москве у вас есть какое-то представительство?  Нет?  Так в городе Королев.  Королев, да?  А как, вы доставляете бесплатно тиражи?  Да, мы бесплатно заберем ваши материалы и бесплатно привезем обратно отпечатанную продукцию.  И вы можете заказать у нас бесплатную печать пилотных образцов, чтобы видеться в дырском качестве нашей работы.  И у нас огромная пара техники, поэтому мы справимся даже с большими заказами,  десятки тысяч листов всего за одну смену.  Вы можете доверять нам крупносрочно заказы.  Ну, для нас это актуально.  Как вас еще раз зовут?  Меня зовут Надежда, а Катерина.  Ну, вы можете какое-то письмо от вас с вашими контактами и с перечислением хотя бы, чем вы занимаетесь.  Ну, типа коммерческое предложение, чтобы это было у меня перед глазами.  Я вышлю вам на расчетчик, у нас есть кое-какие папочки, надо посчитать, шелкографии как раз.  Ну и вообще на будущее.  Скажите, а какие именно услуги вам нужны сейчас?  Ну, шелкографии на пластиковых папках, знаете, такие, на резинках.  Папки на резинки.  Вот, на таких 200 штук шелкографии в один цвет, на синих папках белым.  Ну, такой расчет, это еще не заказ, что был такой расчет от клиента одного.  А, Екатерина, а почему бы нам просто не встретиться?  Наши цели для вас будет презентация предлагания о услуге,  состоит для вас индивидуальное предложение сразу на встрече.  В четверг вам было бы удобно с ним встретиться?  Ну, давайте встретимся.  Ну, то есть он приедет к нам в отцы, да?  Да, конечно.  Давайте, точнее, по какому адресу к вам подъехать?  А у нас на сайте Ренеградский проспект, дом ***, корпус ***, офис ***.  Хорошо. А есть какие-либо особые услуги, чтобы попасть,  можно на форуме пропуска или позвонить с проходной?  Если на машине, то да, за полчаса пусть наберет, я выпишу пропуск.  Просто заранее мы за день не выписываем, нужно обязательно в этот день звонить.  Вот, пропуск на машине.  Поэтому с входом можно с вами...  Да, да, да.  Хорошо. Екатерина, еще вот ответьте, пожалуйста, на несколько вопросов.  Отточните профиль деятельности вашей компании.  Рекламно-агентство.  Хорошо. Вы являетесь производственной или торговойшей организацией?  Мы посредники. У нас нет своего производства.  А какие виды печатных работ вы заказываете?  Ну, наш рекоформатный печат, шелкография, полиграфия, афетный печат, разное.  Солай печат.  Хорошо. Какой максимальный формат, размер печати бывает?  Ну, вы знаете...  А, 2, а, 3?  Сложно сказать. Ну, а 3-я то чаще, наверное, бывает.  Опять-таки, это изделие может быть более, ну, чем у нас.  Ну, а, 3-я то чаще, наверное, бывает.  Ну, а, 3-я то чаще, наверное, бывает.  Опять-таки, это изделие может быть больше, а сама печат может быть меньше.  А второго-то редко.  Хорошо.  То есть, Синдия, вам нужен конечный продукт? Это готовое изделие? Или только печат?  Ну, нам бывает... Ну, допустим, если это у вас по сходной цене, да, допустим,  если вы можете те же папочки нам посчитать, да, вот, ну,  и они у вас будут, ну, там, не очень высокой ценой,  то можем рассмотреть и такой вариант.  Обычно мы, конечно, сами покупаем отдельно сувениры, отдельно нанесения.  Или там же, где покупаем сувениры, там же и наносим.  Но это не всегда так получается.  Поэтому иногда нам нужно только нанесения.  Ну, по-разному, в общем, по зависимости от заказа.  Понятно. А какой средний объем заказа на печать?  Или изготовление граничного изделия?  Знаете, по-разному.  По 200 штук, да, вот сейчас поэтому.  Бывает тысячи, бывает 500, бывает 200.  Ну, в том, что раньше не брать наш маленький заказ, там, увеличивать,  по-разному. Сейчас условия в кризисе, дальше уберемся.  Хорошо, Екатерина, тогда 22-го, это в четверг 22-го октября,  в какое время было бы удобно? В 13 часов было бы удобно?  Ну, либо до 12, либо после двух, вот так.  У нас обеден и кривый час, туда двух.  Сколько там займет эта презентация по времени?  По времени 15-20 минут.  Ну, можно и до часа тогда же.  А, вернее, нет, подожди.  С 12.30 до часа 30 обед, то есть, если в час 30 есть человек,  то можем уже встретиться.  В 13.30? Хорошо, я запишу, в 13.30, 22-го октября.  Наши стали встретиться с вами, с этого адреса.  Всего доброго вам, до свидания.  И вам до свидания.\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Укажите ваш токен Hugging Face\n",
        "    HF_TOKEN = \"Необходим токен Hugging Face для использования pyannote.audio\"\n",
        "\n",
        "    # Инициализация диаризатора\n",
        "    diarizer = SpeechDiarizer(whisper_model=\"medium\", hf_token=HF_TOKEN)\n",
        "\n",
        "    # Обработка аудиофайла\n",
        "    audio_file = \"audio_8.wav\"\n",
        "    result = diarizer.transcribe_and_diarize(audio_file)\n",
        "\n",
        "    # Вывод результатов\n",
        "    formatted_output = diarizer.format_output(result)\n",
        "    print(formatted_output)\n",
        "\n",
        "    # Можно также сохранить результаты в файл\n",
        "    with open(\"audio_8.txt\", \"w\") as f:\n",
        "        f.write(formatted_output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9tAerm5tB81"
      },
      "source": [
        "# Подготовительные кусочки кода"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ws_7eYIiPlCV"
      },
      "source": [
        "### Whisper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGIZkI3VzUxj"
      },
      "source": [
        "https://github.com/openai/whisper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "M2K9oX-_qct9",
        "outputId": "355d9248-ae7d-4c5a-966a-8aa60fa26e21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-iupnynr4\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-iupnynr4\n",
            "  Resolved https://github.com/openai/whisper.git to commit 517a43ecd132a2089d85f4ebc044728a71d49f6e\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (10.6.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (2.0.2)\n",
            "Collecting tiktoken (from openai-whisper==20240930)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (3.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper==20240930) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20240930) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper==20240930) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper==20240930) (3.0.2)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m104.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803708 sha256=93a17a71b6f49a1fb2af12f336fac589bb1d1838d20b2be8bc2db2be8777715a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3nl2l61r/wheels/1f/1d/98/9583695e6695a6ac0ad42d87511097dce5ba486647dbfecb0e\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openai-whisper-20240930 tiktoken-0.9.0\n"
          ]
        }
      ],
      "source": [
        "# загрузить последний коммит Whisper с зависимостями\n",
        "\n",
        "!pip install git+https://github.com/openai/whisper.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTETHcecS94z",
        "outputId": "7c77920b-26af-4221-de6e-f6576264d1ef"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████████████████████████████████| 1.42G/1.42G [00:14<00:00, 104MiB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        }
      ],
      "source": [
        "import whisper\n",
        "\n",
        "model = whisper.load_model(\"medium\")\n",
        "result_1_s = model.transcribe(\"audio_2.mp3\")\n",
        "# продолжительность ~ 11 минут 31 сек"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "collapsed": true,
        "id": "VCMx-rglBGsm",
        "outputId": "469cfa35-3a41-4754-f104-144e2bb245d2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' Добрый день, это магазин товаров для мамы-малышей. Меня зовут Ирина, компания «Фи***и». С кем я могу поговорить по вопросу поставки детских головных уборов? С ума можете поговорить. А как вас зовут? Скажите, пожалуйста. Анастасия. Анастасия, очень приятно. Анастасия, как правило называется ваше должное? Директор. Анастасия, наша компания занимается производством брадажей швейных детских головных уборов. Я звоню, чтобы предложить вам поставки детских шапок на выгодных условиях. Сейчас у нас действует специальное предложение. Если при оформлении заказа в нашем интернет-магазине вы видите кодовое слово, которым пришло специально для вас письме, вы получите в кикне наших продукций 20%. Анастасия, я предлагаю вам пообщаться с нашим ведущим специалистом, который поможет вам пройти регистрацию на нашем сайте и подробно расскажет о продукции и выйдет сотрудничать с нами. Регистрация вас ни к чему не обязывает. А если наш специалист позвонит вам завтра в 14 дня, вас устроит? Нет, мы устроим, потому что у нас специализация другая, мы шапки не очень хотим продавать. То есть, вы шапки не продаёте? У нас есть, но это очень такой штучный товар, и денег на него не заработаешь, поэтому не могу сказать, что мне интересуют ваши предложения. Анастасия, кроме качественных продукций, мы предлагаем скидку 20% на первый заказ. В нашем интернет-магазине только для вашей компании. Именно поэтому я предлагаю пообщаться с нашим специалистом и зарегистрировать вас на сайте. Как вас зовут? Меня зовут Ирина. Ирина, мы работаем с поставщиками, которые нам предлагают 50% за первый заказ. Поэтому 20% я могу с легкостью заказать. Поэтому мне не пишут, что мне это интересно. Анастасия, но вы ещё не смотрели на наши предложения. Упыт показывает, что 70% компании работают с двумя-тремя поставщиками. И это даёт возможность большого выбора, снижает риски и позволяет играть условиями. Это выгодно. Давайте наш специалист вам призвонит, расскажет о том, как вы сооцените с нами, помог и зарегистрируйте вас на сайте. Мы не работаем через посредников. Мы работаем напрямую с поставщиками, с производителями. А мы являемся производителями? Я вам и говорю, что производители, чьи продукции мы, так сказать, пользуемся, чьи продукции мы продаём, предоставляют нам скидку 50%. А, нет. Меня не интересует. Анастасия, но пока вы не знаете, за что платить, любая цена будет высокая. Именно поэтому я предлагаю вам зарегистрироваться на нашем церковном магазине. А наш специалист вам перезвонит, расскажет о наших условиях. А вы сможете сами оценить, что дорого, а что выгодно. Удобно будет пообщаться завтра? Сверху номер. Пушка, я звоню. Анастасия, выточните, пожалуйста, ваши полные фамилии и имя отчества. Анастасия Юрьевна. Анастасия, дайте, пожалуйста, вашу электронную почту для связи. Где вы телефонную взяли? На нашу электронную почту. .ru Можно будет перезвонить на этот же номер? Можно будет. Хорошо, Анастасия. До завтра в 4 часа. Наш канал связывается с вами. Всего доброго, до свидания.'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Компания __ - запикивание инфы\n",
        "result_1_s[\"text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_Jyhovj0LoE",
        "outputId": "ff5c6abe-9d5d-4849-8b3d-36e8c42be886"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': ' Добрый день, это магазин товаров для мамы-малышей. Меня зовут Ирина, компания «Фи***и». С кем я могу поговорить по вопросу поставки детских головных уборов? С ума можете поговорить. А как вас зовут? Скажите, пожалуйста. Анастасия. Анастасия, очень приятно. Анастасия, как правило называется ваше должное? Директор. Анастасия, наша компания занимается производством брадажей швейных детских головных уборов. Я звоню, чтобы предложить вам поставки детских шапок на выгодных условиях. Сейчас у нас действует специальное предложение. Если при оформлении заказа в нашем интернет-магазине вы видите кодовое слово, которым пришло специально для вас письме, вы получите в кикне наших продукций 20%. Анастасия, я предлагаю вам пообщаться с нашим ведущим специалистом, который поможет вам пройти регистрацию на нашем сайте и подробно расскажет о продукции и выйдет сотрудничать с нами. Регистрация вас ни к чему не обязывает. А если наш специалист позвонит вам завтра в 14 дня, вас устроит? Нет, мы устроим, потому что у нас специализация другая, мы шапки не очень хотим продавать. То есть, вы шапки не продаёте? У нас есть, но это очень такой штучный товар, и денег на него не заработаешь, поэтому не могу сказать, что мне интересуют ваши предложения. Анастасия, кроме качественных продукций, мы предлагаем скидку 20% на первый заказ. В нашем интернет-магазине только для вашей компании. Именно поэтому я предлагаю пообщаться с нашим специалистом и зарегистрировать вас на сайте. Как вас зовут? Меня зовут Ирина. Ирина, мы работаем с поставщиками, которые нам предлагают 50% за первый заказ. Поэтому 20% я могу с легкостью заказать. Поэтому мне не пишут, что мне это интересно. Анастасия, но вы ещё не смотрели на наши предложения. Упыт показывает, что 70% компании работают с двумя-тремя поставщиками. И это даёт возможность большого выбора, снижает риски и позволяет играть условиями. Это выгодно. Давайте наш специалист вам призвонит, расскажет о том, как вы сооцените с нами, помог и зарегистрируйте вас на сайте. Мы не работаем через посредников. Мы работаем напрямую с поставщиками, с производителями. А мы являемся производителями? Я вам и говорю, что производители, чьи продукции мы, так сказать, пользуемся, чьи продукции мы продаём, предоставляют нам скидку 50%. А, нет. Меня не интересует. Анастасия, но пока вы не знаете, за что платить, любая цена будет высокая. Именно поэтому я предлагаю вам зарегистрироваться на нашем церковном магазине. А наш специалист вам перезвонит, расскажет о наших условиях. А вы сможете сами оценить, что дорого, а что выгодно. Удобно будет пообщаться завтра? Сверху номер. Пушка, я звоню. Анастасия, выточните, пожалуйста, ваши полные фамилии и имя отчества. Анастасия Юрьевна. Анастасия, дайте, пожалуйста, вашу электронную почту для связи. Где вы телефонную взяли? На нашу электронную почту. .ru Можно будет перезвонить на этот же номер? Можно будет. Хорошо, Анастасия. До завтра в 4 часа. Наш канал связывается с вами. Всего доброго, до свидания.',\n",
              " 'segments': [{'id': 0,\n",
              "   'seek': 0,\n",
              "   'start': 0.0,\n",
              "   'end': 10.0,\n",
              "   'text': ' Добрый день, это магазин товаров для мамы-малышей.',\n",
              "   'tokens': [50364,\n",
              "    3401,\n",
              "    13829,\n",
              "    4851,\n",
              "    13509,\n",
              "    11,\n",
              "    2691,\n",
              "    39771,\n",
              "    2599,\n",
              "    35838,\n",
              "    48708,\n",
              "    5561,\n",
              "    40631,\n",
              "    698,\n",
              "    12,\n",
              "    919,\n",
              "    1218,\n",
              "    12533,\n",
              "    2345,\n",
              "    13,\n",
              "    50864],\n",
              "   'temperature': 0.2,\n",
              "   'avg_logprob': -0.30146130060745496,\n",
              "   'compression_ratio': 1.9094076655052266,\n",
              "   'no_speech_prob': 0.7899643778800964},\n",
              "  {'id': 1,\n",
              "   'seek': 0,\n",
              "   'start': 10.0,\n",
              "   'end': 14.0,\n",
              "   'text': ' Меня зовут Ирина, компания «Фи***и».',\n",
              "   'tokens': [50864,\n",
              "    47311,\n",
              "    46376,\n",
              "    3272,\n",
              "    4679,\n",
              "    1931,\n",
              "    11,\n",
              "    14380,\n",
              "    8831,\n",
              "    4657,\n",
              "    35753,\n",
              "    435,\n",
              "    13684,\n",
              "    435,\n",
              "    12513,\n",
              "    51064],\n",
              "   'temperature': 0.2,\n",
              "   'avg_logprob': -0.30146130060745496,\n",
              "   'compression_ratio': 1.9094076655052266,\n",
              "   'no_speech_prob': 0.7899643778800964},\n",
              "  {'id': 2,\n",
              "   'seek': 0,\n",
              "   'start': 14.0,\n",
              "   'end': 19.0,\n",
              "   'text': ' С кем я могу поговорить по вопросу поставки детских головных уборов?',\n",
              "   'tokens': [51064,\n",
              "    2933,\n",
              "    981,\n",
              "    1504,\n",
              "    2552,\n",
              "    22951,\n",
              "    38858,\n",
              "    3258,\n",
              "    2801,\n",
              "    17611,\n",
              "    585,\n",
              "    28072,\n",
              "    2241,\n",
              "    15079,\n",
              "    25698,\n",
              "    24721,\n",
              "    5783,\n",
              "    13853,\n",
              "    19716,\n",
              "    30,\n",
              "    51314],\n",
              "   'temperature': 0.2,\n",
              "   'avg_logprob': -0.30146130060745496,\n",
              "   'compression_ratio': 1.9094076655052266,\n",
              "   'no_speech_prob': 0.7899643778800964},\n",
              "  {'id': 3,\n",
              "   'seek': 0,\n",
              "   'start': 19.0,\n",
              "   'end': 21.0,\n",
              "   'text': ' С ума можете поговорить.',\n",
              "   'tokens': [51314, 2933, 1595, 14229, 23578, 38858, 3258, 13, 51414],\n",
              "   'temperature': 0.2,\n",
              "   'avg_logprob': -0.30146130060745496,\n",
              "   'compression_ratio': 1.9094076655052266,\n",
              "   'no_speech_prob': 0.7899643778800964},\n",
              "  {'id': 4,\n",
              "   'seek': 0,\n",
              "   'start': 21.0,\n",
              "   'end': 23.0,\n",
              "   'text': ' А как вас зовут? Скажите, пожалуйста.',\n",
              "   'tokens': [51414,\n",
              "    3450,\n",
              "    3014,\n",
              "    10655,\n",
              "    46376,\n",
              "    30,\n",
              "    22965,\n",
              "    3234,\n",
              "    5878,\n",
              "    11,\n",
              "    32518,\n",
              "    13,\n",
              "    51514],\n",
              "   'temperature': 0.2,\n",
              "   'avg_logprob': -0.30146130060745496,\n",
              "   'compression_ratio': 1.9094076655052266,\n",
              "   'no_speech_prob': 0.7899643778800964},\n",
              "  {'id': 5,\n",
              "   'seek': 0,\n",
              "   'start': 23.0,\n",
              "   'end': 25.0,\n",
              "   'text': ' Анастасия.',\n",
              "   'tokens': [51514, 3450, 1931, 982, 2019, 7409, 13, 51614],\n",
              "   'temperature': 0.2,\n",
              "   'avg_logprob': -0.30146130060745496,\n",
              "   'compression_ratio': 1.9094076655052266,\n",
              "   'no_speech_prob': 0.7899643778800964},\n",
              "  {'id': 6,\n",
              "   'seek': 0,\n",
              "   'start': 25.0,\n",
              "   'end': 29.0,\n",
              "   'text': ' Анастасия, очень приятно. Анастасия, как правило называется ваше должное?',\n",
              "   'tokens': [51614,\n",
              "    3450,\n",
              "    1931,\n",
              "    982,\n",
              "    2019,\n",
              "    7409,\n",
              "    11,\n",
              "    6730,\n",
              "    5082,\n",
              "    19005,\n",
              "    13,\n",
              "    3450,\n",
              "    1931,\n",
              "    982,\n",
              "    2019,\n",
              "    7409,\n",
              "    11,\n",
              "    3014,\n",
              "    10615,\n",
              "    22201,\n",
              "    40659,\n",
              "    740,\n",
              "    386,\n",
              "    5246,\n",
              "    12220,\n",
              "    6126,\n",
              "    30,\n",
              "    51814],\n",
              "   'temperature': 0.2,\n",
              "   'avg_logprob': -0.30146130060745496,\n",
              "   'compression_ratio': 1.9094076655052266,\n",
              "   'no_speech_prob': 0.7899643778800964},\n",
              "  {'id': 7,\n",
              "   'seek': 2900,\n",
              "   'start': 29.0,\n",
              "   'end': 31.0,\n",
              "   'text': ' Директор.',\n",
              "   'tokens': [50364, 3401, 4490, 39867, 13, 50464],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.17572594927502916,\n",
              "   'compression_ratio': 2.125319693094629,\n",
              "   'no_speech_prob': 0.08143783360719681},\n",
              "  {'id': 8,\n",
              "   'seek': 2900,\n",
              "   'start': 31.0,\n",
              "   'end': 36.0,\n",
              "   'text': ' Анастасия, наша компания занимается производством брадажей швейных детских головных уборов.',\n",
              "   'tokens': [50464,\n",
              "    3450,\n",
              "    1931,\n",
              "    982,\n",
              "    2019,\n",
              "    7409,\n",
              "    11,\n",
              "    48513,\n",
              "    14380,\n",
              "    8831,\n",
              "    25396,\n",
              "    6970,\n",
              "    28685,\n",
              "    38450,\n",
              "    19603,\n",
              "    2601,\n",
              "    3234,\n",
              "    2345,\n",
              "    5941,\n",
              "    859,\n",
              "    2345,\n",
              "    5783,\n",
              "    15079,\n",
              "    25698,\n",
              "    24721,\n",
              "    5783,\n",
              "    13853,\n",
              "    19716,\n",
              "    13,\n",
              "    50714],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.17572594927502916,\n",
              "   'compression_ratio': 2.125319693094629,\n",
              "   'no_speech_prob': 0.08143783360719681},\n",
              "  {'id': 9,\n",
              "   'seek': 2900,\n",
              "   'start': 36.0,\n",
              "   'end': 41.0,\n",
              "   'text': ' Я звоню, чтобы предложить вам поставки детских шапок на выгодных условиях.',\n",
              "   'tokens': [50714,\n",
              "    4857,\n",
              "    45832,\n",
              "    1148,\n",
              "    11,\n",
              "    7887,\n",
              "    40373,\n",
              "    3258,\n",
              "    10448,\n",
              "    28072,\n",
              "    2241,\n",
              "    15079,\n",
              "    25698,\n",
              "    5941,\n",
              "    4219,\n",
              "    2637,\n",
              "    1470,\n",
              "    2840,\n",
              "    1906,\n",
              "    1435,\n",
              "    5783,\n",
              "    34974,\n",
              "    32176,\n",
              "    13,\n",
              "    50964],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.17572594927502916,\n",
              "   'compression_ratio': 2.125319693094629,\n",
              "   'no_speech_prob': 0.08143783360719681},\n",
              "  {'id': 10,\n",
              "   'seek': 2900,\n",
              "   'start': 41.0,\n",
              "   'end': 44.0,\n",
              "   'text': ' Сейчас у нас действует специальное предложение.',\n",
              "   'tokens': [50964,\n",
              "    23590,\n",
              "    1595,\n",
              "    6519,\n",
              "    17136,\n",
              "    17781,\n",
              "    25665,\n",
              "    33322,\n",
              "    40373,\n",
              "    5627,\n",
              "    13,\n",
              "    51114],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.17572594927502916,\n",
              "   'compression_ratio': 2.125319693094629,\n",
              "   'no_speech_prob': 0.08143783360719681},\n",
              "  {'id': 11,\n",
              "   'seek': 2900,\n",
              "   'start': 44.0,\n",
              "   'end': 48.0,\n",
              "   'text': ' Если при оформлении заказа в нашем интернет-магазине вы видите кодовое слово,',\n",
              "   'tokens': [51114,\n",
              "    12412,\n",
              "    5082,\n",
              "    1000,\n",
              "    18190,\n",
              "    693,\n",
              "    15573,\n",
              "    10264,\n",
              "    1990,\n",
              "    386,\n",
              "    740,\n",
              "    48181,\n",
              "    12073,\n",
              "    27021,\n",
              "    12,\n",
              "    919,\n",
              "    5583,\n",
              "    1990,\n",
              "    20998,\n",
              "    2840,\n",
              "    41904,\n",
              "    981,\n",
              "    1435,\n",
              "    1055,\n",
              "    5805,\n",
              "    43272,\n",
              "    11,\n",
              "    51314],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.17572594927502916,\n",
              "   'compression_ratio': 2.125319693094629,\n",
              "   'no_speech_prob': 0.08143783360719681},\n",
              "  {'id': 12,\n",
              "   'seek': 2900,\n",
              "   'start': 48.0,\n",
              "   'end': 54.0,\n",
              "   'text': ' которым пришло специально для вас письме, вы получите в кикне наших продукций 20%.',\n",
              "   'tokens': [51314,\n",
              "    4388,\n",
              "    11250,\n",
              "    22448,\n",
              "    4610,\n",
              "    25665,\n",
              "    10986,\n",
              "    5561,\n",
              "    10655,\n",
              "    713,\n",
              "    10363,\n",
              "    30522,\n",
              "    11,\n",
              "    2840,\n",
              "    9478,\n",
              "    5878,\n",
              "    740,\n",
              "    981,\n",
              "    3605,\n",
              "    4677,\n",
              "    41525,\n",
              "    33873,\n",
              "    42495,\n",
              "    945,\n",
              "    6856,\n",
              "    51614],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.17572594927502916,\n",
              "   'compression_ratio': 2.125319693094629,\n",
              "   'no_speech_prob': 0.08143783360719681},\n",
              "  {'id': 13,\n",
              "   'seek': 2900,\n",
              "   'start': 54.0,\n",
              "   'end': 57.0,\n",
              "   'text': ' Анастасия, я предлагаю вам пообщаться с нашим ведущим специалистом,',\n",
              "   'tokens': [51614,\n",
              "    3450,\n",
              "    1931,\n",
              "    982,\n",
              "    2019,\n",
              "    7409,\n",
              "    11,\n",
              "    2552,\n",
              "    46841,\n",
              "    3776,\n",
              "    10448,\n",
              "    2801,\n",
              "    32977,\n",
              "    8525,\n",
              "    776,\n",
              "    8253,\n",
              "    2165,\n",
              "    35126,\n",
              "    17263,\n",
              "    2165,\n",
              "    25665,\n",
              "    36948,\n",
              "    1253,\n",
              "    11,\n",
              "    51764],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.17572594927502916,\n",
              "   'compression_ratio': 2.125319693094629,\n",
              "   'no_speech_prob': 0.08143783360719681},\n",
              "  {'id': 14,\n",
              "   'seek': 5700,\n",
              "   'start': 57.0,\n",
              "   'end': 62.0,\n",
              "   'text': ' который поможет вам пройти регистрацию на нашем сайте и подробно расскажет о продукции',\n",
              "   'tokens': [50364,\n",
              "    11897,\n",
              "    8613,\n",
              "    22180,\n",
              "    10448,\n",
              "    1285,\n",
              "    44213,\n",
              "    31235,\n",
              "    9330,\n",
              "    3580,\n",
              "    24718,\n",
              "    1470,\n",
              "    48181,\n",
              "    776,\n",
              "    10330,\n",
              "    1006,\n",
              "    4095,\n",
              "    17129,\n",
              "    1234,\n",
              "    17399,\n",
              "    3234,\n",
              "    1094,\n",
              "    1000,\n",
              "    33873,\n",
              "    12502,\n",
              "    50614],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.11869042205810547,\n",
              "   'compression_ratio': 2.0163398692810457,\n",
              "   'no_speech_prob': 0.21804097294807434},\n",
              "  {'id': 15,\n",
              "   'seek': 5700,\n",
              "   'start': 62.0,\n",
              "   'end': 64.0,\n",
              "   'text': ' и выйдет сотрудничать с нами.',\n",
              "   'tokens': [50614,\n",
              "    1006,\n",
              "    42132,\n",
              "    856,\n",
              "    1094,\n",
              "    50233,\n",
              "    27996,\n",
              "    2209,\n",
              "    776,\n",
              "    44552,\n",
              "    13,\n",
              "    50714],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.11869042205810547,\n",
              "   'compression_ratio': 2.0163398692810457,\n",
              "   'no_speech_prob': 0.21804097294807434},\n",
              "  {'id': 16,\n",
              "   'seek': 5700,\n",
              "   'start': 64.0,\n",
              "   'end': 66.0,\n",
              "   'text': ' Регистрация вас ни к чему не обязывает.',\n",
              "   'tokens': [50714,\n",
              "    6325,\n",
              "    4953,\n",
              "    9330,\n",
              "    3580,\n",
              "    17651,\n",
              "    10655,\n",
              "    13686,\n",
              "    981,\n",
              "    1358,\n",
              "    8339,\n",
              "    1725,\n",
              "    27945,\n",
              "    29277,\n",
              "    13,\n",
              "    50814],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.11869042205810547,\n",
              "   'compression_ratio': 2.0163398692810457,\n",
              "   'no_speech_prob': 0.21804097294807434},\n",
              "  {'id': 17,\n",
              "   'seek': 5700,\n",
              "   'start': 66.0,\n",
              "   'end': 71.0,\n",
              "   'text': ' А если наш специалист позвонит вам завтра в 14 дня, вас устроит?',\n",
              "   'tokens': [50814,\n",
              "    3450,\n",
              "    8042,\n",
              "    8253,\n",
              "    25665,\n",
              "    36948,\n",
              "    12188,\n",
              "    39672,\n",
              "    1635,\n",
              "    10448,\n",
              "    13388,\n",
              "    37397,\n",
              "    740,\n",
              "    3499,\n",
              "    36115,\n",
              "    11,\n",
              "    10655,\n",
              "    1595,\n",
              "    14086,\n",
              "    1635,\n",
              "    30,\n",
              "    51064],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.11869042205810547,\n",
              "   'compression_ratio': 2.0163398692810457,\n",
              "   'no_speech_prob': 0.21804097294807434},\n",
              "  {'id': 18,\n",
              "   'seek': 5700,\n",
              "   'start': 71.0,\n",
              "   'end': 75.0,\n",
              "   'text': ' Нет, мы устроим, потому что у нас специализация другая,',\n",
              "   'tokens': [51064,\n",
              "    21249,\n",
              "    11,\n",
              "    4777,\n",
              "    1595,\n",
              "    14086,\n",
              "    2165,\n",
              "    11,\n",
              "    11919,\n",
              "    2143,\n",
              "    1595,\n",
              "    6519,\n",
              "    25665,\n",
              "    28105,\n",
              "    21235,\n",
              "    8435,\n",
              "    4251,\n",
              "    11,\n",
              "    51264],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.11869042205810547,\n",
              "   'compression_ratio': 2.0163398692810457,\n",
              "   'no_speech_prob': 0.21804097294807434},\n",
              "  {'id': 19,\n",
              "   'seek': 5700,\n",
              "   'start': 75.0,\n",
              "   'end': 78.0,\n",
              "   'text': ' мы шапки не очень хотим продавать.',\n",
              "   'tokens': [51264,\n",
              "    4777,\n",
              "    5941,\n",
              "    4219,\n",
              "    2241,\n",
              "    1725,\n",
              "    6730,\n",
              "    11515,\n",
              "    2165,\n",
              "    11354,\n",
              "    38945,\n",
              "    13,\n",
              "    51414],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.11869042205810547,\n",
              "   'compression_ratio': 2.0163398692810457,\n",
              "   'no_speech_prob': 0.21804097294807434},\n",
              "  {'id': 20,\n",
              "   'seek': 5700,\n",
              "   'start': 78.0,\n",
              "   'end': 81.0,\n",
              "   'text': ' То есть, вы шапки не продаёте?',\n",
              "   'tokens': [51414,\n",
              "    16047,\n",
              "    5640,\n",
              "    11,\n",
              "    2840,\n",
              "    5941,\n",
              "    4219,\n",
              "    2241,\n",
              "    1725,\n",
              "    11354,\n",
              "    386,\n",
              "    2882,\n",
              "    5863,\n",
              "    30,\n",
              "    51564],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.11869042205810547,\n",
              "   'compression_ratio': 2.0163398692810457,\n",
              "   'no_speech_prob': 0.21804097294807434},\n",
              "  {'id': 21,\n",
              "   'seek': 8100,\n",
              "   'start': 82.0,\n",
              "   'end': 86.0,\n",
              "   'text': ' У нас есть, но это очень такой штучный товар,',\n",
              "   'tokens': [50414,\n",
              "    6523,\n",
              "    6519,\n",
              "    5640,\n",
              "    11,\n",
              "    6035,\n",
              "    2691,\n",
              "    6730,\n",
              "    13452,\n",
              "    28826,\n",
              "    4187,\n",
              "    4441,\n",
              "    35838,\n",
              "    2222,\n",
              "    11,\n",
              "    50614],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.20753843134099786,\n",
              "   'compression_ratio': 1.5822784810126582,\n",
              "   'no_speech_prob': 0.6379695534706116},\n",
              "  {'id': 22,\n",
              "   'seek': 8100,\n",
              "   'start': 86.0,\n",
              "   'end': 90.0,\n",
              "   'text': ' и денег на него не заработаешь,',\n",
              "   'tokens': [50614,\n",
              "    1006,\n",
              "    40957,\n",
              "    1470,\n",
              "    15052,\n",
              "    1725,\n",
              "    17821,\n",
              "    7237,\n",
              "    17266,\n",
              "    11,\n",
              "    50814],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.20753843134099786,\n",
              "   'compression_ratio': 1.5822784810126582,\n",
              "   'no_speech_prob': 0.6379695534706116},\n",
              "  {'id': 23,\n",
              "   'seek': 8100,\n",
              "   'start': 90.0,\n",
              "   'end': 95.0,\n",
              "   'text': ' поэтому не могу сказать, что мне интересуют ваши предложения.',\n",
              "   'tokens': [50814,\n",
              "    19698,\n",
              "    1725,\n",
              "    22951,\n",
              "    20636,\n",
              "    11,\n",
              "    2143,\n",
              "    8531,\n",
              "    15033,\n",
              "    23588,\n",
              "    48375,\n",
              "    40373,\n",
              "    5332,\n",
              "    13,\n",
              "    51064],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.20753843134099786,\n",
              "   'compression_ratio': 1.5822784810126582,\n",
              "   'no_speech_prob': 0.6379695534706116},\n",
              "  {'id': 24,\n",
              "   'seek': 9500,\n",
              "   'start': 96.0,\n",
              "   'end': 101.0,\n",
              "   'text': ' Анастасия, кроме качественных продукций, мы предлагаем скидку 20% на первый заказ.',\n",
              "   'tokens': [50414,\n",
              "    3450,\n",
              "    1931,\n",
              "    982,\n",
              "    2019,\n",
              "    7409,\n",
              "    11,\n",
              "    7502,\n",
              "    45540,\n",
              "    28595,\n",
              "    12134,\n",
              "    5783,\n",
              "    33873,\n",
              "    42495,\n",
              "    11,\n",
              "    4777,\n",
              "    46841,\n",
              "    7906,\n",
              "    776,\n",
              "    2241,\n",
              "    856,\n",
              "    4401,\n",
              "    945,\n",
              "    4,\n",
              "    1470,\n",
              "    30025,\n",
              "    10264,\n",
              "    1990,\n",
              "    13,\n",
              "    50664],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.11352384192311865,\n",
              "   'compression_ratio': 1.9647435897435896,\n",
              "   'no_speech_prob': 0.6594470143318176},\n",
              "  {'id': 25,\n",
              "   'seek': 9500,\n",
              "   'start': 101.0,\n",
              "   'end': 104.0,\n",
              "   'text': ' В нашем интернет-магазине только для вашей компании.',\n",
              "   'tokens': [50664,\n",
              "    2348,\n",
              "    48181,\n",
              "    12073,\n",
              "    27021,\n",
              "    12,\n",
              "    919,\n",
              "    5583,\n",
              "    1990,\n",
              "    20998,\n",
              "    9008,\n",
              "    5561,\n",
              "    14536,\n",
              "    2345,\n",
              "    44231,\n",
              "    13,\n",
              "    50814],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.11352384192311865,\n",
              "   'compression_ratio': 1.9647435897435896,\n",
              "   'no_speech_prob': 0.6594470143318176},\n",
              "  {'id': 26,\n",
              "   'seek': 9500,\n",
              "   'start': 104.0,\n",
              "   'end': 109.0,\n",
              "   'text': ' Именно поэтому я предлагаю пообщаться с нашим специалистом и зарегистрировать вас на сайте.',\n",
              "   'tokens': [50814,\n",
              "    34759,\n",
              "    6855,\n",
              "    19698,\n",
              "    2552,\n",
              "    46841,\n",
              "    3776,\n",
              "    2801,\n",
              "    32977,\n",
              "    8525,\n",
              "    776,\n",
              "    8253,\n",
              "    2165,\n",
              "    25665,\n",
              "    36948,\n",
              "    1253,\n",
              "    1006,\n",
              "    17821,\n",
              "    4953,\n",
              "    435,\n",
              "    5530,\n",
              "    26411,\n",
              "    10655,\n",
              "    1470,\n",
              "    776,\n",
              "    10330,\n",
              "    13,\n",
              "    51064],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.11352384192311865,\n",
              "   'compression_ratio': 1.9647435897435896,\n",
              "   'no_speech_prob': 0.6594470143318176},\n",
              "  {'id': 27,\n",
              "   'seek': 9500,\n",
              "   'start': 109.0,\n",
              "   'end': 110.0,\n",
              "   'text': ' Как вас зовут?',\n",
              "   'tokens': [51064, 11011, 10655, 46376, 30, 51114],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.11352384192311865,\n",
              "   'compression_ratio': 1.9647435897435896,\n",
              "   'no_speech_prob': 0.6594470143318176},\n",
              "  {'id': 28,\n",
              "   'seek': 9500,\n",
              "   'start': 110.0,\n",
              "   'end': 112.0,\n",
              "   'text': ' Меня зовут Ирина.',\n",
              "   'tokens': [51114, 47311, 46376, 3272, 4679, 1931, 13, 51214],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.11352384192311865,\n",
              "   'compression_ratio': 1.9647435897435896,\n",
              "   'no_speech_prob': 0.6594470143318176},\n",
              "  {'id': 29,\n",
              "   'seek': 9500,\n",
              "   'start': 112.0,\n",
              "   'end': 118.0,\n",
              "   'text': ' Ирина, мы работаем с поставщиками, которые нам предлагают 50% за первый заказ.',\n",
              "   'tokens': [51214,\n",
              "    3272,\n",
              "    4679,\n",
              "    1931,\n",
              "    11,\n",
              "    4777,\n",
              "    9197,\n",
              "    7906,\n",
              "    776,\n",
              "    28072,\n",
              "    2000,\n",
              "    3605,\n",
              "    5150,\n",
              "    11,\n",
              "    10381,\n",
              "    11401,\n",
              "    46841,\n",
              "    6406,\n",
              "    2625,\n",
              "    4,\n",
              "    4396,\n",
              "    30025,\n",
              "    10264,\n",
              "    1990,\n",
              "    13,\n",
              "    51514],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.11352384192311865,\n",
              "   'compression_ratio': 1.9647435897435896,\n",
              "   'no_speech_prob': 0.6594470143318176},\n",
              "  {'id': 30,\n",
              "   'seek': 11800,\n",
              "   'start': 118.0,\n",
              "   'end': 123.0,\n",
              "   'text': ' Поэтому 20% я могу с легкостью заказать.',\n",
              "   'tokens': [50364,\n",
              "    22318,\n",
              "    945,\n",
              "    4,\n",
              "    2552,\n",
              "    22951,\n",
              "    776,\n",
              "    39995,\n",
              "    3167,\n",
              "    1148,\n",
              "    10264,\n",
              "    1990,\n",
              "    2209,\n",
              "    13,\n",
              "    50614],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.27508691069367647,\n",
              "   'compression_ratio': 1.9539641943734016,\n",
              "   'no_speech_prob': 0.4674558937549591},\n",
              "  {'id': 31,\n",
              "   'seek': 11800,\n",
              "   'start': 123.0,\n",
              "   'end': 127.0,\n",
              "   'text': ' Поэтому мне не пишут, что мне это интересно.',\n",
              "   'tokens': [50614,\n",
              "    22318,\n",
              "    8531,\n",
              "    1725,\n",
              "    37979,\n",
              "    3767,\n",
              "    11,\n",
              "    2143,\n",
              "    8531,\n",
              "    2691,\n",
              "    33333,\n",
              "    13,\n",
              "    50814],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.27508691069367647,\n",
              "   'compression_ratio': 1.9539641943734016,\n",
              "   'no_speech_prob': 0.4674558937549591},\n",
              "  {'id': 32,\n",
              "   'seek': 11800,\n",
              "   'start': 127.0,\n",
              "   'end': 130.0,\n",
              "   'text': ' Анастасия, но вы ещё не смотрели на наши предложения.',\n",
              "   'tokens': [50814,\n",
              "    3450,\n",
              "    1931,\n",
              "    982,\n",
              "    2019,\n",
              "    7409,\n",
              "    11,\n",
              "    6035,\n",
              "    2840,\n",
              "    13993,\n",
              "    1725,\n",
              "    17726,\n",
              "    8334,\n",
              "    1470,\n",
              "    36314,\n",
              "    40373,\n",
              "    5332,\n",
              "    13,\n",
              "    50964],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.27508691069367647,\n",
              "   'compression_ratio': 1.9539641943734016,\n",
              "   'no_speech_prob': 0.4674558937549591},\n",
              "  {'id': 33,\n",
              "   'seek': 11800,\n",
              "   'start': 130.0,\n",
              "   'end': 134.0,\n",
              "   'text': ' Упыт показывает, что 70% компании работают с двумя-тремя поставщиками.',\n",
              "   'tokens': [50964,\n",
              "    6523,\n",
              "    1354,\n",
              "    14043,\n",
              "    34614,\n",
              "    3310,\n",
              "    11,\n",
              "    2143,\n",
              "    5285,\n",
              "    4,\n",
              "    44231,\n",
              "    9197,\n",
              "    6406,\n",
              "    776,\n",
              "    7196,\n",
              "    5525,\n",
              "    681,\n",
              "    12,\n",
              "    403,\n",
              "    7049,\n",
              "    681,\n",
              "    28072,\n",
              "    2000,\n",
              "    3605,\n",
              "    5150,\n",
              "    13,\n",
              "    51164],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.27508691069367647,\n",
              "   'compression_ratio': 1.9539641943734016,\n",
              "   'no_speech_prob': 0.4674558937549591},\n",
              "  {'id': 34,\n",
              "   'seek': 11800,\n",
              "   'start': 134.0,\n",
              "   'end': 136.0,\n",
              "   'text': ' И это даёт возможность большого выбора,',\n",
              "   'tokens': [51164,\n",
              "    3272,\n",
              "    2691,\n",
              "    8995,\n",
              "    11950,\n",
              "    41233,\n",
              "    12457,\n",
              "    2350,\n",
              "    18061,\n",
              "    22889,\n",
              "    11,\n",
              "    51264],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.27508691069367647,\n",
              "   'compression_ratio': 1.9539641943734016,\n",
              "   'no_speech_prob': 0.4674558937549591},\n",
              "  {'id': 35,\n",
              "   'seek': 11800,\n",
              "   'start': 136.0,\n",
              "   'end': 138.0,\n",
              "   'text': ' снижает риски и позволяет играть условиями.',\n",
              "   'tokens': [51264,\n",
              "    776,\n",
              "    1903,\n",
              "    1820,\n",
              "    3310,\n",
              "    31393,\n",
              "    2241,\n",
              "    1006,\n",
              "    28805,\n",
              "    27516,\n",
              "    14568,\n",
              "    2209,\n",
              "    34974,\n",
              "    7409,\n",
              "    6293,\n",
              "    13,\n",
              "    51364],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.27508691069367647,\n",
              "   'compression_ratio': 1.9539641943734016,\n",
              "   'no_speech_prob': 0.4674558937549591},\n",
              "  {'id': 36,\n",
              "   'seek': 11800,\n",
              "   'start': 138.0,\n",
              "   'end': 139.0,\n",
              "   'text': ' Это выгодно.',\n",
              "   'tokens': [51364, 6684, 2840, 1906, 44356, 13, 51414],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.27508691069367647,\n",
              "   'compression_ratio': 1.9539641943734016,\n",
              "   'no_speech_prob': 0.4674558937549591},\n",
              "  {'id': 37,\n",
              "   'seek': 11800,\n",
              "   'start': 139.0,\n",
              "   'end': 142.0,\n",
              "   'text': ' Давайте наш специалист вам призвонит, расскажет о том,',\n",
              "   'tokens': [51414,\n",
              "    30487,\n",
              "    8253,\n",
              "    25665,\n",
              "    36948,\n",
              "    10448,\n",
              "    26724,\n",
              "    39672,\n",
              "    1635,\n",
              "    11,\n",
              "    17399,\n",
              "    3234,\n",
              "    1094,\n",
              "    1000,\n",
              "    13294,\n",
              "    11,\n",
              "    51564],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.27508691069367647,\n",
              "   'compression_ratio': 1.9539641943734016,\n",
              "   'no_speech_prob': 0.4674558937549591},\n",
              "  {'id': 38,\n",
              "   'seek': 11800,\n",
              "   'start': 142.0,\n",
              "   'end': 145.0,\n",
              "   'text': ' как вы сооцените с нами, помог и зарегистрируйте вас на сайте.',\n",
              "   'tokens': [51564,\n",
              "    3014,\n",
              "    2840,\n",
              "    7425,\n",
              "    354,\n",
              "    23447,\n",
              "    5878,\n",
              "    776,\n",
              "    44552,\n",
              "    11,\n",
              "    27097,\n",
              "    1006,\n",
              "    17821,\n",
              "    4953,\n",
              "    435,\n",
              "    5530,\n",
              "    20517,\n",
              "    1644,\n",
              "    5863,\n",
              "    10655,\n",
              "    1470,\n",
              "    776,\n",
              "    10330,\n",
              "    13,\n",
              "    51714],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.27508691069367647,\n",
              "   'compression_ratio': 1.9539641943734016,\n",
              "   'no_speech_prob': 0.4674558937549591},\n",
              "  {'id': 39,\n",
              "   'seek': 14500,\n",
              "   'start': 146.0,\n",
              "   'end': 149.0,\n",
              "   'text': ' Мы не работаем через посредников.',\n",
              "   'tokens': [50414,\n",
              "    12726,\n",
              "    1725,\n",
              "    9197,\n",
              "    7906,\n",
              "    17341,\n",
              "    5810,\n",
              "    10278,\n",
              "    22122,\n",
              "    13,\n",
              "    50564],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.20016675525241429,\n",
              "   'compression_ratio': 2.036144578313253,\n",
              "   'no_speech_prob': 0.6483606696128845},\n",
              "  {'id': 40,\n",
              "   'seek': 14500,\n",
              "   'start': 149.0,\n",
              "   'end': 152.0,\n",
              "   'text': ' Мы работаем напрямую с поставщиками, с производителями.',\n",
              "   'tokens': [50564,\n",
              "    12726,\n",
              "    9197,\n",
              "    7906,\n",
              "    18296,\n",
              "    10531,\n",
              "    3924,\n",
              "    776,\n",
              "    28072,\n",
              "    2000,\n",
              "    3605,\n",
              "    5150,\n",
              "    11,\n",
              "    776,\n",
              "    28685,\n",
              "    36491,\n",
              "    6293,\n",
              "    13,\n",
              "    50714],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.20016675525241429,\n",
              "   'compression_ratio': 2.036144578313253,\n",
              "   'no_speech_prob': 0.6483606696128845},\n",
              "  {'id': 41,\n",
              "   'seek': 14500,\n",
              "   'start': 152.0,\n",
              "   'end': 154.0,\n",
              "   'text': ' А мы являемся производителями?',\n",
              "   'tokens': [50714,\n",
              "    3450,\n",
              "    4777,\n",
              "    19028,\n",
              "    2873,\n",
              "    40811,\n",
              "    28685,\n",
              "    36491,\n",
              "    6293,\n",
              "    30,\n",
              "    50814],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.20016675525241429,\n",
              "   'compression_ratio': 2.036144578313253,\n",
              "   'no_speech_prob': 0.6483606696128845},\n",
              "  {'id': 42,\n",
              "   'seek': 14500,\n",
              "   'start': 154.0,\n",
              "   'end': 159.0,\n",
              "   'text': ' Я вам и говорю, что производители,',\n",
              "   'tokens': [50814,\n",
              "    4857,\n",
              "    10448,\n",
              "    1006,\n",
              "    34931,\n",
              "    11,\n",
              "    2143,\n",
              "    28685,\n",
              "    29084,\n",
              "    11,\n",
              "    51064],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.20016675525241429,\n",
              "   'compression_ratio': 2.036144578313253,\n",
              "   'no_speech_prob': 0.6483606696128845},\n",
              "  {'id': 43,\n",
              "   'seek': 14500,\n",
              "   'start': 159.0,\n",
              "   'end': 164.0,\n",
              "   'text': ' чьи продукции мы, так сказать, пользуемся,',\n",
              "   'tokens': [51064,\n",
              "    1358,\n",
              "    678,\n",
              "    435,\n",
              "    33873,\n",
              "    12502,\n",
              "    4777,\n",
              "    11,\n",
              "    2936,\n",
              "    20636,\n",
              "    11,\n",
              "    30419,\n",
              "    33096,\n",
              "    1679,\n",
              "    11,\n",
              "    51314],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.20016675525241429,\n",
              "   'compression_ratio': 2.036144578313253,\n",
              "   'no_speech_prob': 0.6483606696128845},\n",
              "  {'id': 44,\n",
              "   'seek': 14500,\n",
              "   'start': 164.0,\n",
              "   'end': 166.0,\n",
              "   'text': ' чьи продукции мы продаём,',\n",
              "   'tokens': [51314,\n",
              "    1358,\n",
              "    678,\n",
              "    435,\n",
              "    33873,\n",
              "    12502,\n",
              "    4777,\n",
              "    11354,\n",
              "    386,\n",
              "    12868,\n",
              "    11,\n",
              "    51414],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.20016675525241429,\n",
              "   'compression_ratio': 2.036144578313253,\n",
              "   'no_speech_prob': 0.6483606696128845},\n",
              "  {'id': 45,\n",
              "   'seek': 14500,\n",
              "   'start': 166.0,\n",
              "   'end': 169.0,\n",
              "   'text': ' предоставляют нам скидку 50%.',\n",
              "   'tokens': [51414,\n",
              "    8048,\n",
              "    354,\n",
              "    17560,\n",
              "    7329,\n",
              "    11401,\n",
              "    776,\n",
              "    2241,\n",
              "    856,\n",
              "    4401,\n",
              "    2625,\n",
              "    6856,\n",
              "    51564],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.20016675525241429,\n",
              "   'compression_ratio': 2.036144578313253,\n",
              "   'no_speech_prob': 0.6483606696128845},\n",
              "  {'id': 46,\n",
              "   'seek': 14500,\n",
              "   'start': 169.0,\n",
              "   'end': 171.0,\n",
              "   'text': ' А, нет.',\n",
              "   'tokens': [51564, 3450, 11, 9916, 13, 51664],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.20016675525241429,\n",
              "   'compression_ratio': 2.036144578313253,\n",
              "   'no_speech_prob': 0.6483606696128845},\n",
              "  {'id': 47,\n",
              "   'seek': 14500,\n",
              "   'start': 171.0,\n",
              "   'end': 173.0,\n",
              "   'text': ' Меня не интересует.',\n",
              "   'tokens': [51664, 47311, 1725, 15033, 17781, 13, 51764],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.20016675525241429,\n",
              "   'compression_ratio': 2.036144578313253,\n",
              "   'no_speech_prob': 0.6483606696128845},\n",
              "  {'id': 48,\n",
              "   'seek': 17300,\n",
              "   'start': 173.0,\n",
              "   'end': 176.0,\n",
              "   'text': ' Анастасия, но пока вы не знаете, за что платить,',\n",
              "   'tokens': [50364,\n",
              "    3450,\n",
              "    1931,\n",
              "    982,\n",
              "    2019,\n",
              "    7409,\n",
              "    11,\n",
              "    6035,\n",
              "    17770,\n",
              "    2840,\n",
              "    1725,\n",
              "    29868,\n",
              "    11,\n",
              "    4396,\n",
              "    2143,\n",
              "    34160,\n",
              "    3258,\n",
              "    11,\n",
              "    50514],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.20853644519595047,\n",
              "   'compression_ratio': 2.1265206812652067,\n",
              "   'no_speech_prob': 0.24533966183662415},\n",
              "  {'id': 49,\n",
              "   'seek': 17300,\n",
              "   'start': 176.0,\n",
              "   'end': 178.0,\n",
              "   'text': ' любая цена будет высокая.',\n",
              "   'tokens': [50514, 9875, 4251, 5188, 13362, 7306, 35998, 4251, 13, 50614],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.20853644519595047,\n",
              "   'compression_ratio': 2.1265206812652067,\n",
              "   'no_speech_prob': 0.24533966183662415},\n",
              "  {'id': 50,\n",
              "   'seek': 17300,\n",
              "   'start': 178.0,\n",
              "   'end': 180.0,\n",
              "   'text': ' Именно поэтому я предлагаю вам зарегистрироваться',\n",
              "   'tokens': [50614,\n",
              "    34759,\n",
              "    6855,\n",
              "    19698,\n",
              "    2552,\n",
              "    46841,\n",
              "    3776,\n",
              "    10448,\n",
              "    17821,\n",
              "    4953,\n",
              "    435,\n",
              "    5530,\n",
              "    10214,\n",
              "    8525,\n",
              "    50714],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.20853644519595047,\n",
              "   'compression_ratio': 2.1265206812652067,\n",
              "   'no_speech_prob': 0.24533966183662415},\n",
              "  {'id': 51,\n",
              "   'seek': 17300,\n",
              "   'start': 180.0,\n",
              "   'end': 181.0,\n",
              "   'text': ' на нашем церковном магазине.',\n",
              "   'tokens': [50714,\n",
              "    1470,\n",
              "    48181,\n",
              "    5188,\n",
              "    1135,\n",
              "    7718,\n",
              "    9950,\n",
              "    39771,\n",
              "    20998,\n",
              "    13,\n",
              "    50764],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.20853644519595047,\n",
              "   'compression_ratio': 2.1265206812652067,\n",
              "   'no_speech_prob': 0.24533966183662415},\n",
              "  {'id': 52,\n",
              "   'seek': 17300,\n",
              "   'start': 181.0,\n",
              "   'end': 183.0,\n",
              "   'text': ' А наш специалист вам перезвонит,',\n",
              "   'tokens': [50764,\n",
              "    3450,\n",
              "    8253,\n",
              "    25665,\n",
              "    36948,\n",
              "    10448,\n",
              "    4321,\n",
              "    3634,\n",
              "    39672,\n",
              "    1635,\n",
              "    11,\n",
              "    50864],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.20853644519595047,\n",
              "   'compression_ratio': 2.1265206812652067,\n",
              "   'no_speech_prob': 0.24533966183662415},\n",
              "  {'id': 53,\n",
              "   'seek': 17300,\n",
              "   'start': 183.0,\n",
              "   'end': 184.0,\n",
              "   'text': ' расскажет о наших условиях.',\n",
              "   'tokens': [50864, 17399, 3234, 1094, 1000, 41525, 34974, 32176, 13, 50914],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.20853644519595047,\n",
              "   'compression_ratio': 2.1265206812652067,\n",
              "   'no_speech_prob': 0.24533966183662415},\n",
              "  {'id': 54,\n",
              "   'seek': 17300,\n",
              "   'start': 184.0,\n",
              "   'end': 187.0,\n",
              "   'text': ' А вы сможете сами оценить, что дорого, а что выгодно.',\n",
              "   'tokens': [50914,\n",
              "    3450,\n",
              "    2840,\n",
              "    47044,\n",
              "    10524,\n",
              "    34085,\n",
              "    1000,\n",
              "    1814,\n",
              "    44436,\n",
              "    11,\n",
              "    2143,\n",
              "    18478,\n",
              "    2350,\n",
              "    11,\n",
              "    2559,\n",
              "    2143,\n",
              "    2840,\n",
              "    1906,\n",
              "    44356,\n",
              "    13,\n",
              "    51064],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.20853644519595047,\n",
              "   'compression_ratio': 2.1265206812652067,\n",
              "   'no_speech_prob': 0.24533966183662415},\n",
              "  {'id': 55,\n",
              "   'seek': 17300,\n",
              "   'start': 187.0,\n",
              "   'end': 189.0,\n",
              "   'text': ' Удобно будет пообщаться завтра?',\n",
              "   'tokens': [51064,\n",
              "    6523,\n",
              "    856,\n",
              "    2061,\n",
              "    1234,\n",
              "    7306,\n",
              "    2801,\n",
              "    32977,\n",
              "    8525,\n",
              "    13388,\n",
              "    37397,\n",
              "    30,\n",
              "    51164],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.20853644519595047,\n",
              "   'compression_ratio': 2.1265206812652067,\n",
              "   'no_speech_prob': 0.24533966183662415},\n",
              "  {'id': 56,\n",
              "   'seek': 17300,\n",
              "   'start': 189.0,\n",
              "   'end': 190.0,\n",
              "   'text': ' Сверху номер.',\n",
              "   'tokens': [51164, 2933, 10327, 1157, 585, 36847, 1135, 13, 51214],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.20853644519595047,\n",
              "   'compression_ratio': 2.1265206812652067,\n",
              "   'no_speech_prob': 0.24533966183662415},\n",
              "  {'id': 57,\n",
              "   'seek': 17300,\n",
              "   'start': 190.0,\n",
              "   'end': 191.0,\n",
              "   'text': ' Пушка, я звоню.',\n",
              "   'tokens': [51214, 2608, 34187, 11, 2552, 45832, 1148, 13, 51264],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.20853644519595047,\n",
              "   'compression_ratio': 2.1265206812652067,\n",
              "   'no_speech_prob': 0.24533966183662415},\n",
              "  {'id': 58,\n",
              "   'seek': 17300,\n",
              "   'start': 191.0,\n",
              "   'end': 193.0,\n",
              "   'text': ' Анастасия, выточните, пожалуйста,',\n",
              "   'tokens': [51264,\n",
              "    3450,\n",
              "    1931,\n",
              "    982,\n",
              "    2019,\n",
              "    7409,\n",
              "    11,\n",
              "    2840,\n",
              "    20483,\n",
              "    38066,\n",
              "    11,\n",
              "    32518,\n",
              "    11,\n",
              "    51364],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.20853644519595047,\n",
              "   'compression_ratio': 2.1265206812652067,\n",
              "   'no_speech_prob': 0.24533966183662415},\n",
              "  {'id': 59,\n",
              "   'seek': 17300,\n",
              "   'start': 193.0,\n",
              "   'end': 195.0,\n",
              "   'text': ' ваши полные фамилии и имя отчества.',\n",
              "   'tokens': [51364,\n",
              "    48375,\n",
              "    4692,\n",
              "    4970,\n",
              "    4394,\n",
              "    5150,\n",
              "    1675,\n",
              "    435,\n",
              "    1006,\n",
              "    7604,\n",
              "    681,\n",
              "    2943,\n",
              "    32595,\n",
              "    12115,\n",
              "    13,\n",
              "    51464],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.20853644519595047,\n",
              "   'compression_ratio': 2.1265206812652067,\n",
              "   'no_speech_prob': 0.24533966183662415},\n",
              "  {'id': 60,\n",
              "   'seek': 17300,\n",
              "   'start': 195.0,\n",
              "   'end': 197.0,\n",
              "   'text': ' Анастасия Юрьевна.',\n",
              "   'tokens': [51464,\n",
              "    3450,\n",
              "    1931,\n",
              "    982,\n",
              "    2019,\n",
              "    7409,\n",
              "    27002,\n",
              "    28659,\n",
              "    3515,\n",
              "    1931,\n",
              "    13,\n",
              "    51564],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.20853644519595047,\n",
              "   'compression_ratio': 2.1265206812652067,\n",
              "   'no_speech_prob': 0.24533966183662415},\n",
              "  {'id': 61,\n",
              "   'seek': 17300,\n",
              "   'start': 197.0,\n",
              "   'end': 199.0,\n",
              "   'text': ' Анастасия, дайте, пожалуйста,',\n",
              "   'tokens': [51564,\n",
              "    3450,\n",
              "    1931,\n",
              "    982,\n",
              "    2019,\n",
              "    7409,\n",
              "    11,\n",
              "    1070,\n",
              "    10330,\n",
              "    11,\n",
              "    32518,\n",
              "    11,\n",
              "    51664],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.20853644519595047,\n",
              "   'compression_ratio': 2.1265206812652067,\n",
              "   'no_speech_prob': 0.24533966183662415},\n",
              "  {'id': 62,\n",
              "   'seek': 17300,\n",
              "   'start': 199.0,\n",
              "   'end': 201.0,\n",
              "   'text': ' вашу электронную почту для связи.',\n",
              "   'tokens': [51664,\n",
              "    14536,\n",
              "    585,\n",
              "    31314,\n",
              "    23753,\n",
              "    9882,\n",
              "    12079,\n",
              "    13549,\n",
              "    5561,\n",
              "    22430,\n",
              "    435,\n",
              "    13,\n",
              "    51764],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.20853644519595047,\n",
              "   'compression_ratio': 2.1265206812652067,\n",
              "   'no_speech_prob': 0.24533966183662415},\n",
              "  {'id': 63,\n",
              "   'seek': 20100,\n",
              "   'start': 201.0,\n",
              "   'end': 203.0,\n",
              "   'text': ' Где вы телефонную взяли?',\n",
              "   'tokens': [50364, 41996, 2840, 44485, 9882, 11892, 24559, 30, 50464],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.31651664502692944,\n",
              "   'compression_ratio': 1.450261780104712,\n",
              "   'no_speech_prob': 0.12360958009958267},\n",
              "  {'id': 64,\n",
              "   'seek': 20100,\n",
              "   'start': 203.0,\n",
              "   'end': 205.0,\n",
              "   'text': ' На нашу электронную почту.',\n",
              "   'tokens': [50464,\n",
              "    11245,\n",
              "    8253,\n",
              "    585,\n",
              "    31314,\n",
              "    23753,\n",
              "    9882,\n",
              "    12079,\n",
              "    13549,\n",
              "    13,\n",
              "    50564],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.31651664502692944,\n",
              "   'compression_ratio': 1.450261780104712,\n",
              "   'no_speech_prob': 0.12360958009958267},\n",
              "  {'id': 65,\n",
              "   'seek': 20100,\n",
              "   'start': 205.0,\n",
              "   'end': 207.0,\n",
              "   'text': ' .ru',\n",
              "   'tokens': [50564, 2411, 894, 50664],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.31651664502692944,\n",
              "   'compression_ratio': 1.450261780104712,\n",
              "   'no_speech_prob': 0.12360958009958267},\n",
              "  {'id': 66,\n",
              "   'seek': 20100,\n",
              "   'start': 207.0,\n",
              "   'end': 209.0,\n",
              "   'text': ' Можно будет перезвонить на этот же номер?',\n",
              "   'tokens': [50664,\n",
              "    34423,\n",
              "    7306,\n",
              "    4321,\n",
              "    3634,\n",
              "    39672,\n",
              "    3258,\n",
              "    1470,\n",
              "    11508,\n",
              "    6151,\n",
              "    36847,\n",
              "    1135,\n",
              "    30,\n",
              "    50764],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.31651664502692944,\n",
              "   'compression_ratio': 1.450261780104712,\n",
              "   'no_speech_prob': 0.12360958009958267},\n",
              "  {'id': 67,\n",
              "   'seek': 20100,\n",
              "   'start': 209.0,\n",
              "   'end': 211.0,\n",
              "   'text': ' Можно будет.',\n",
              "   'tokens': [50764, 34423, 7306, 13, 50864],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.31651664502692944,\n",
              "   'compression_ratio': 1.450261780104712,\n",
              "   'no_speech_prob': 0.12360958009958267},\n",
              "  {'id': 68,\n",
              "   'seek': 20100,\n",
              "   'start': 211.0,\n",
              "   'end': 213.0,\n",
              "   'text': ' Хорошо, Анастасия.',\n",
              "   'tokens': [50864, 37564, 11, 3450, 1931, 982, 2019, 7409, 13, 50964],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.31651664502692944,\n",
              "   'compression_ratio': 1.450261780104712,\n",
              "   'no_speech_prob': 0.12360958009958267},\n",
              "  {'id': 69,\n",
              "   'seek': 21300,\n",
              "   'start': 213.0,\n",
              "   'end': 215.0,\n",
              "   'text': ' До завтра в 4 часа.',\n",
              "   'tokens': [50364, 31695, 13388, 37397, 740, 1017, 13562, 386, 13, 50464],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.437045415242513,\n",
              "   'compression_ratio': 1.2477064220183487,\n",
              "   'no_speech_prob': 0.9677448868751526},\n",
              "  {'id': 70,\n",
              "   'seek': 21300,\n",
              "   'start': 215.0,\n",
              "   'end': 217.0,\n",
              "   'text': ' Наш канал связывается с вами.',\n",
              "   'tokens': [50464,\n",
              "    2410,\n",
              "    6835,\n",
              "    28597,\n",
              "    22430,\n",
              "    4655,\n",
              "    6970,\n",
              "    776,\n",
              "    24166,\n",
              "    13,\n",
              "    50564],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.437045415242513,\n",
              "   'compression_ratio': 1.2477064220183487,\n",
              "   'no_speech_prob': 0.9677448868751526},\n",
              "  {'id': 71,\n",
              "   'seek': 21300,\n",
              "   'start': 217.0,\n",
              "   'end': 219.0,\n",
              "   'text': ' Всего доброго, до свидания.',\n",
              "   'tokens': [50564,\n",
              "    10779,\n",
              "    4353,\n",
              "    35620,\n",
              "    2350,\n",
              "    11,\n",
              "    5865,\n",
              "    43666,\n",
              "    8831,\n",
              "    13,\n",
              "    50664],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.437045415242513,\n",
              "   'compression_ratio': 1.2477064220183487,\n",
              "   'no_speech_prob': 0.9677448868751526}],\n",
              " 'language': 'ru'}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result_1_s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWw1DDkf0GBp",
        "outputId": "40da53c6-7843-40ce-a0c0-58896bbc682f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████████████████████████████████| 1.42G/1.42G [00:26<00:00, 57.8MiB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        }
      ],
      "source": [
        "model = whisper.load_model(\"medium\")\n",
        "result_1_m = model.transcribe(\"audio_1.mp3\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "collapsed": true,
        "id": "ZW7XUzyQElOH",
        "outputId": "0b4e5e58-fd9f-47d5-d67f-73e016d120c1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' Здравствуйте! Благодарим вас за звонок в нашу компанию. Пожалуйста, наберите внутренний номер сотрудника в Тоновом режиме. Если вы хотите отправить факс, нажмите 0 или дождитесь ответа оператора. Компания ***. Добрый день. Добрый день. Меня зовут Елена. Компания ***. Скажите, кто у вас занимается сайтом компании? В общем, можно поговорить? Скажите, пожалуйста, как вас зовут? Елена. Очень приятно. Елена, наша компания увеличивает переток клиентов из интернета. Мы предлагаем вам комплексное продвижение вашего сайта. Сгорайте выводов топ-10. Все наши клиенты в 4-6 раз увеличили количество звонков и заявок с сайта, причем многие сократили свои расходы на рекламу до 50%. Также у нас есть вариант продвижения, при котором вы платите только за результат. Это продвижение с оплатой за действие или с оплатой за тратик. Елена, скажите, какой у вас примерный бюджет на рекламу? Пока сложно сказать. Вы отправите предложение на ***. Да, конечно, Елена. Я вышлю вам наше общее коммерческое предложение. Пока наш специалист может пообщаться с вами, подробнее рассказать о выгоде сотрудничества с нами. Скажите, например, среду вам будет удобно в первой половине дня? Во второй. Хорошо, во второй половине дня. Елена, скажите, пожалуйста, ваше отчество? Николаевна. Елена Николаевна, есть ли прямой номер телефона, по которому можно с вами связаться или звонить на этот же? На этот же. Назовите адрес электронной почты для того, чтобы я могла отправить вам коммерческое предложение. ***.мэл.ру Скажите, пожалуйста, вы уже продвигаете сайт с кем-то? Пока нет. Назовите название вашего сайта. ***.про Скажите, пожалуйста, регион продвижения? Требовского мэл.ру Хорошо. Елена Николаевна, тогда в среду, 28 декабря, наш специалист будет с вами во второй половине дня. А пока отправлю вам информационный материал. Всего доброго, до свидания. До свидания.'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Компания *** - запикивание инфы\n",
        "result_1_m['text']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUKk4Ytj61gH"
      },
      "source": [
        "### Ускоренный Whisper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-tIDlOX639o",
        "outputId": "341526be-fb58-4be6-93e2-1a70a1aa8621"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: faster-whisper in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "Requirement already satisfied: ctranslate2<5,>=4.0 in /usr/local/lib/python3.11/dist-packages (from faster-whisper) (4.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.13 in /usr/local/lib/python3.11/dist-packages (from faster-whisper) (0.30.1)\n",
            "Requirement already satisfied: tokenizers<1,>=0.13 in /usr/local/lib/python3.11/dist-packages (from faster-whisper) (0.21.1)\n",
            "Requirement already satisfied: onnxruntime<2,>=1.14 in /usr/local/lib/python3.11/dist-packages (from faster-whisper) (1.21.0)\n",
            "Requirement already satisfied: av>=11 in /usr/local/lib/python3.11/dist-packages (from faster-whisper) (14.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from faster-whisper) (4.67.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (2.0.2)\n",
            "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.11/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper) (4.13.1)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (5.29.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (1.13.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper) (10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (2025.1.31)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper) (1.3.0)\n",
            " Добрый день, это магазин товаров для мамы-малышей.\n",
            " Меня зовут Ирина, компания «Фиа».\n",
            " С кем я могу поговорить по вопросу поставки детских головных уборов?\n",
            " С ума можете поговорить.\n",
            " А как вас зовут? Скажите, пожалуйста.\n",
            " Анастасия.\n",
            " Анастасия, очень приятно. Анастасия, как правило называется ваше должное?\n",
            " Директор.\n",
            " Анастасия, наша компания занимается производством бородажей швейных детских головных уборов.\n",
            " Я звоню, чтобы предложить вам поставки детских шапок на выгодных условиях.\n",
            " Сейчас у нас действует специальное предложение.\n",
            " Если при оформлении заказа в нашем интернет-магазине вы видите кодовое слово,\n",
            " которым пришло специально для вас в письме, вы получите скидку на наши продукции 20%.\n",
            " Анастасия, я предлагаю вам пообщаться с нашим ведущим специалистом,\n",
            " который поможет вам пройти регистрацию на нашем сайте и подробно расскажет о продукции\n",
            " и выйдет сотрудничать с нами.\n",
            " Регистрация вас ни к чему не обязывает.\n",
            " А если наш специалист позвонит вам завтра в 14 дня, вас устроит?\n",
            " Нет, нас устроит, потому что у нас специализация другая,\n",
            " мы шапки не очень хотим продавать.\n",
            " То есть, вы шапки не продаёте?\n",
            " У нас есть, но это очень такой штучный товар и денег на него не заработаешь,\n",
            " поэтому не могу сказать, что мне интересуют ваши предложения.\n",
            " Анастасия, кроме качественных продукций мы предлагаем скидку 20% на первый заказ.\n",
            " В нашем интернет-магазине только для вашей компании.\n",
            " Именно поэтому я предлагаю пообщаться с нашим специалистом\n",
            " и зарегистрировать вас на сайте.\n",
            " Как вас зовут?\n",
            " Меня зовут Ирина.\n",
            " Ирина, мы работаем с поставщиками, которые нам предлагают 50% за первый заказ.\n",
            " Поэтому 20% я могу с легкостью заказать.\n",
            " Поэтому мне не слишком это интересно.\n",
            " Анастасия, но вы ещё не смотрели на наши предложения.\n",
            " Вы подпоказываете, что 70% компании работают с двумя, тремя поставщиками.\n",
            " Это даёт возможность большого выбора, снижает риски и позволяет играть условиями.\n",
            " Это выгодно.\n",
            " Давайте нашим специалистом перезвонить, расскажет о том,\n",
            " как вы разрешите нам помочь зарегистрировать вас на сайте.\n",
            " Мы не работаем через посредников.\n",
            " Мы работаем напрямую с поставщиками, с производителями.\n",
            " А мы являемся производителями.\n",
            " Я вам и говорю, что производители,\n",
            " чьи продукции мы продаём,\n",
            " предоставляют нам скидку 50%.\n",
            " Меня не интересует.\n",
            " Анастасия, но пока вы не знаете, за что платите,\n",
            " любая цена будет высокой.\n",
            " Именно поэтому я предлагаю вам зарегистрироваться в нашем магазине.\n",
            " А наш специалист вам перезвонит и расскажет о наших условиях.\n",
            " А вы сможете сами оценить, что дорого, а что выгодно.\n",
            " Удобно будет пообщаться завтра?\n",
            " 17 минут.\n",
            " Отвечните, пожалуйста, ваши полные фамилии и имя, отчество.\n",
            " Анастасия Юрьевна.\n",
            " Анастасия, дайте, пожалуйста, вашу электронную почту для связи.\n",
            " Где вы телефонную взяли?\n",
            " На нашу электронную почту.\n",
            " Можно будет перезвонить на этот же номер?\n",
            " Можно будет.\n",
            " Хорошо, Анастасия.\n",
            " Тогда завтра в 14.00 наш специалист связится с вами.\n",
            " Всего доброго, до свидания.\n",
            " До свидания.\n"
          ]
        }
      ],
      "source": [
        "!pip install faster-whisper\n",
        "from faster_whisper import WhisperModel\n",
        "\n",
        "model = WhisperModel(\"medium\", compute_type=\"int8\")  # int8/fp16\n",
        "segments, _ = model.transcribe(\"audio_5.mp3\")\n",
        "for seg in segments:\n",
        "    print(seg.text)\n",
        "\n",
        "# время вполнения ~ 9 минут 23 секунды"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFaFjO8W_m1M"
      },
      "outputs": [],
      "source": [
        "for seg in segments:\n",
        "    print(seg.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6NPGe-IHXY2"
      },
      "source": [
        "### Диаризация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QEE8g5oL0mc"
      },
      "source": [
        "https://github.com/pyannote/pyannote-audio?tab=readme-ov-file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "qAbm0nMoHa-B",
        "outputId": "3cca9750-47ce-46bd-d2b2-e261b60f25d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyannote.audio\n",
            "  Downloading pyannote.audio-3.3.2-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting asteroid-filterbanks>=0.4 (from pyannote.audio)\n",
            "  Downloading asteroid_filterbanks-0.4.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (0.8.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (0.30.1)\n",
            "Collecting lightning>=2.0.1 (from pyannote.audio)\n",
            "  Downloading lightning-2.5.1-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting omegaconf<3.0,>=2.1 (from pyannote.audio)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting pyannote.core>=5.0.0 (from pyannote.audio)\n",
            "  Downloading pyannote.core-5.0.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting pyannote.database>=5.0.1 (from pyannote.audio)\n",
            "  Downloading pyannote.database-5.1.3-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pyannote.metrics>=3.2 (from pyannote.audio)\n",
            "  Downloading pyannote.metrics-3.2.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting pyannote.pipeline>=3.0.1 (from pyannote.audio)\n",
            "  Downloading pyannote.pipeline-3.0.1-py3-none-any.whl.metadata (897 bytes)\n",
            "Collecting pytorch-metric-learning>=2.1.0 (from pyannote.audio)\n",
            "  Downloading pytorch_metric_learning-2.8.1-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (13.9.4)\n",
            "Collecting semver>=3.0.0 (from pyannote.audio)\n",
            "  Downloading semver-3.0.4-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (0.13.1)\n",
            "Collecting speechbrain>=1.0.0 (from pyannote.audio)\n",
            "  Downloading speechbrain-1.0.3-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting tensorboardX>=2.6 (from pyannote.audio)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (2.6.0+cu124)\n",
            "Collecting torch-audiomentations>=0.11.0 (from pyannote.audio)\n",
            "  Downloading torch_audiomentations-0.12.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: torchaudio>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (2.6.0+cu124)\n",
            "Collecting torchmetrics>=0.11.0 (from pyannote.audio)\n",
            "  Downloading torchmetrics-1.7.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from asteroid-filterbanks>=0.4->pyannote.audio) (2.0.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from asteroid-filterbanks>=0.4->pyannote.audio) (4.13.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (4.67.1)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning>=2.0.1->pyannote.audio)\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting pytorch-lightning (from lightning>=2.0.1->pyannote.audio)\n",
            "  Downloading pytorch_lightning-2.5.1-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf<3.0,>=2.1->pyannote.audio)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: sortedcontainers>=2.0.4 in /usr/local/lib/python3.11/dist-packages (from pyannote.core>=5.0.0->pyannote.audio) (2.4.0)\n",
            "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.core>=5.0.0->pyannote.audio) (1.14.1)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.11/dist-packages (from pyannote.database>=5.0.1->pyannote.audio) (2.2.2)\n",
            "Requirement already satisfied: typer>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.database>=5.0.1->pyannote.audio) (0.15.2)\n",
            "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (1.6.1)\n",
            "Collecting docopt>=0.6.2 (from pyannote.metrics>=3.2->pyannote.audio)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (0.9.0)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (3.10.0)\n",
            "Requirement already satisfied: sympy>=1.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (1.13.1)\n",
            "Collecting optuna>=3.1 (from pyannote.pipeline>=3.0.1->pyannote.audio)\n",
            "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.0.0->pyannote.audio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.0.0->pyannote.audio) (2.18.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->pyannote.audio) (1.17.1)\n",
            "Collecting hyperpyyaml (from speechbrain>=1.0.0->pyannote.audio)\n",
            "  Downloading HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from speechbrain>=1.0.0->pyannote.audio) (1.4.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from speechbrain>=1.0.0->pyannote.audio) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX>=2.6->pyannote.audio) (5.29.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (3.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.1->pyannote.metrics>=3.2->pyannote.audio) (1.3.0)\n",
            "Collecting julius<0.3,>=0.2.3 (from torch-audiomentations>=0.11.0->pyannote.audio)\n",
            "  Downloading julius-0.2.7.tar.gz (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-pitch-shift>=1.2.2 (from torch-audiomentations>=0.11.0->pyannote.audio)\n",
            "  Downloading torch_pitch_shift-1.2.5-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->pyannote.audio) (2.22)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (3.11.15)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning>=2.0.1->pyannote.audio) (75.2.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->pyannote.audio) (0.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (2.8.2)\n",
            "Collecting alembic>=1.5.0 (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio)\n",
            "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (2.0.40)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.17.1->pyannote.metrics>=3.2->pyannote.audio) (3.6.0)\n",
            "Collecting primePy>=1.3 (from torch-pitch-shift>=1.2.2->torch-audiomentations>=0.11.0->pyannote.audio)\n",
            "  Downloading primePy-1.3-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio) (1.5.4)\n",
            "Collecting ruamel.yaml>=0.17.28 (from hyperpyyaml->speechbrain>=1.0.0->pyannote.audio)\n",
            "  Downloading ruamel.yaml-0.18.10-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->pyannote.audio) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (2025.1.31)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.18.3)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (1.1.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.17.0)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=1.0.0->pyannote.audio)\n",
            "  Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (3.1.1)\n",
            "Downloading pyannote.audio-3.3.2-py2.py3-none-any.whl (898 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m898.7/898.7 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asteroid_filterbanks-0.4.0-py3-none-any.whl (29 kB)\n",
            "Downloading lightning-2.5.1-py3-none-any.whl (818 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m818.9/818.9 kB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyannote.core-5.0.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyannote.database-5.1.3-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyannote.metrics-3.2.1-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyannote.pipeline-3.0.1-py3-none-any.whl (31 kB)\n",
            "Downloading pytorch_metric_learning-2.8.1-py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.9/125.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semver-3.0.4-py3-none-any.whl (17 kB)\n",
            "Downloading speechbrain-1.0.3-py3-none-any.whl (864 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m864.1/864.1 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_audiomentations-0.12.0-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.7.1-py3-none-any.whl (961 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_pitch_shift-1.2.5-py3-none-any.whl (5.0 kB)\n",
            "Downloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n",
            "Downloading pytorch_lightning-2.5.1-py3-none-any.whl (822 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.0/823.0 kB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading primePy-1.3-py3-none-any.whl (4.0 kB)\n",
            "Downloading ruamel.yaml-0.18.10-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (739 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: antlr4-python3-runtime, docopt, julius\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=427c10278c1b52570323b2a20cfc1139325d350b6a1bbde3b178556edf54cdb0\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=ee10cef6e48b85f25838ef4259a8be61f69d1cd87f800d92483257da1e09949a\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
            "  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for julius: filename=julius-0.2.7-py3-none-any.whl size=21870 sha256=21788ad921e243fab86375edcd9792e6c895c927b419bd7e165493cd1179f76a\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/15/d4/edd724cefe78050a6ba3344b8b0c6672db829a799dbb9f81ff\n",
            "Successfully built antlr4-python3-runtime docopt julius\n",
            "Installing collected packages: primePy, docopt, antlr4-python3-runtime, tensorboardX, semver, ruamel.yaml.clib, omegaconf, lightning-utilities, colorlog, ruamel.yaml, pyannote.core, alembic, optuna, hyperpyyaml, torchmetrics, pytorch-metric-learning, pyannote.database, julius, asteroid-filterbanks, torch-pitch-shift, speechbrain, pytorch-lightning, pyannote.pipeline, pyannote.metrics, torch-audiomentations, lightning, pyannote.audio\n",
            "Successfully installed alembic-1.15.2 antlr4-python3-runtime-4.9.3 asteroid-filterbanks-0.4.0 colorlog-6.9.0 docopt-0.6.2 hyperpyyaml-1.2.2 julius-0.2.7 lightning-2.5.1 lightning-utilities-0.14.3 omegaconf-2.3.0 optuna-4.2.1 primePy-1.3 pyannote.audio-3.3.2 pyannote.core-5.0.0 pyannote.database-5.1.3 pyannote.metrics-3.2.1 pyannote.pipeline-3.0.1 pytorch-lightning-2.5.1 pytorch-metric-learning-2.8.1 ruamel.yaml-0.18.10 ruamel.yaml.clib-0.2.12 semver-3.0.4 speechbrain-1.0.3 tensorboardX-2.6.2.2 torch-audiomentations-0.12.0 torch-pitch-shift-1.2.5 torchmetrics-1.7.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "1302ee48f49245c7aff1629d5ccba11b",
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install pyannote.audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mg77qMchMJhv"
      },
      "outputs": [],
      "source": [
        "import torchaudio\n",
        "\n",
        "# Конвертация MP3 в WAV\n",
        "waveform, sample_rate = torchaudio.load(\"audio_2.mp3\")\n",
        "torchaudio.save(\"audio_2.wav\", waveform, sample_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281,
          "referenced_widgets": [
            "6e51b7d0bf0d4b5da21ba0d51be02a95",
            "25bc6a5b2f8e4b26b291570834186916",
            "4075c13bd969492daec3fca92d66ce11",
            "71786e70a4a640f28e47505966941716",
            "c9a0658e8a8343d880cb883d3af9d5a2",
            "59c4dd37c2d94c4f9260f78eb5fb99fc",
            "9d2a27323a52452d8ea00ba3bec0d8a4",
            "a6e6b53f092f46f9bae9f7763589bd1b",
            "90dff87964e34563a1d7d885cbe5691f",
            "5186c74dc1aa47209a24a6c63864cdec",
            "eafdb00f20684e1f859fded6baab015d",
            "9bbf12000f744c699e96c06d76db4549",
            "248ddd7db65141a9a1efbaa9a9ddeef3",
            "4da97bcae597421aa6bbbb7e49bd07ea",
            "43d3a98bf3fc4d828a745939e333bd15",
            "f2a60e781b4e401e8dc56ee8ea44cf43",
            "84b2d413b872446285ab01250474f502",
            "82301003a35e42189b3660f1d6c753ef",
            "f42f1bf6811d49f58103615672ad4f1c",
            "06b17a36df034c9eaeab8a42574cf773",
            "4e9de951956a4924ac717c2d33b3580b",
            "87a027d9cded44ba92bb1e5dde014c5e",
            "8ab9a25471c742d69ad8b7b0af94844c",
            "8e0fcbfec99640829d2f16984ebcad66",
            "df90995d606d48a39f401b3899cbb3d3",
            "5cd9bab718ef4f999e5d4248d7dcb212",
            "c6cbb1d2168b4558908be22374241fc5",
            "df3d827da1c044ed85eb5f7067206b1d",
            "e772304c69e24c6fad7f47c239ef04ea",
            "c6fbb1419e784ab889337a4caaf87c2d",
            "29d739daf2174af2be322a6397bfb77c",
            "b693180dff7a441fac5aad545ef4f53e",
            "248e22efa80c493ca3c2d29fafc8a961",
            "6d5912a4cc8740c887fca68af713874a",
            "24d9e14ff6af402f9239007294c4e46e",
            "2959c2ee84174193950a989b6ff59d70",
            "6fe60b7ad2a94890b1ff8ba223e9148d",
            "0b875ba0fd634619b8427b1cef31e0e8",
            "35f61379fce949e1b84038b295d5e137",
            "bd649642bd684207be372bd733595113",
            "c22cd0359611478ab2d3ba1ede548201",
            "d89288125b2942bb8463ff608aa3b5f1",
            "91fd9118c2ed4d8eb3c8345eb45aac01",
            "e2308566350a4bbc9148db5957220fdc",
            "062e4a03a91e4afd921e6797f47e7eec",
            "17aa96183fb540d7bfd31fadb962de4f",
            "8ba35415ddd44cfa838b5af9629b6bf4",
            "85553ced5d3e488eb1eeb649cd99594a",
            "86a0af961ded4990bdc25d201537734c",
            "ccf450aafc32413192a48963af5d16b3",
            "b9a6dba9fb3640a081114f55e4e3790c",
            "abd706b7527a4266a4662137405ad53d",
            "45259112edde4f6a9a47559d91bcd531",
            "df282dda1fcc4364b3349c68cb3288ad",
            "180d77b32d3f4bf08c07b2d36cbe5d9f"
          ]
        },
        "id": "g-1vICIGHZ5z",
        "outputId": "a683cf01-11ce-4054-9ce4-1dbc040ca938"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e51b7d0bf0d4b5da21ba0d51be02a95",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.yaml:   0%|          | 0.00/469 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for _speechbrain_save\n",
            "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for _speechbrain_load\n",
            "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for save\n",
            "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for load\n",
            "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for _save\n",
            "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for _recover\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9bbf12000f744c699e96c06d76db4549",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/5.91M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ab9a25471c742d69ad8b7b0af94844c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.yaml:   0%|          | 0.00/399 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6d5912a4cc8740c887fca68af713874a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/26.6M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "062e4a03a91e4afd921e6797f47e7eec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.yaml:   0%|          | 0.00/221 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from pyannote.audio import Pipeline\n",
        "pipeline = Pipeline.from_pretrained(\n",
        "    \"pyannote/speaker-diarization-3.1\",\n",
        "    use_auth_token=\"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\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-iEOFanIWZx",
        "outputId": "9f2e6d91-e63d-4530-9db4-de911b0bb48b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pyannote/audio/models/blocks/pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)\n",
            "  std = sequences.std(dim=-1, correction=1)\n"
          ]
        }
      ],
      "source": [
        "# apply pretrained pipeline\n",
        "diarization = pipeline(\"audio_2.wav\")\n",
        "\n",
        "# выполнялось ~13 мин 14 сек"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "xWnZkzvR25sZ",
        "outputId": "f0131259-748a-4410-d863-af4f5d4638bb"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<pyannote.core.annotation.Annotation at 0x7c0a8a119690>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "diarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mRZuYp_uKfv6",
        "outputId": "80e56653-d181-4f88-b04d-b01a5be3b769"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "start=3.9s stop=4.3s speaker_SPEAKER_00\n",
            "start=4.3s stop=4.6s speaker_SPEAKER_01\n",
            "start=4.6s stop=7.8s speaker_SPEAKER_00\n",
            "start=9.9s stop=11.0s speaker_SPEAKER_00\n",
            "start=11.3s stop=13.0s speaker_SPEAKER_00\n",
            "start=14.0s stop=17.3s speaker_SPEAKER_00\n",
            "start=19.3s stop=20.6s speaker_SPEAKER_00\n",
            "start=20.9s stop=22.8s speaker_SPEAKER_00\n",
            "start=23.8s stop=24.6s speaker_SPEAKER_00\n",
            "start=25.0s stop=28.5s speaker_SPEAKER_00\n",
            "start=30.1s stop=30.7s speaker_SPEAKER_00\n",
            "start=31.6s stop=36.4s speaker_SPEAKER_00\n",
            "start=36.7s stop=39.6s speaker_SPEAKER_00\n",
            "start=40.5s stop=41.7s speaker_SPEAKER_00\n",
            "start=42.0s stop=44.4s speaker_SPEAKER_00\n",
            "start=44.6s stop=48.8s speaker_SPEAKER_00\n",
            "start=48.9s stop=51.2s speaker_SPEAKER_00\n",
            "start=51.3s stop=53.8s speaker_SPEAKER_00\n",
            "start=54.5s stop=60.6s speaker_SPEAKER_00\n",
            "start=60.8s stop=63.9s speaker_SPEAKER_00\n",
            "start=64.1s stop=66.0s speaker_SPEAKER_00\n",
            "start=66.4s stop=69.8s speaker_SPEAKER_00\n",
            "start=70.3s stop=71.3s speaker_SPEAKER_00\n",
            "start=72.4s stop=75.9s speaker_SPEAKER_01\n",
            "start=76.7s stop=78.5s speaker_SPEAKER_01\n",
            "start=79.6s stop=81.5s speaker_SPEAKER_01\n",
            "start=80.7s stop=81.3s speaker_SPEAKER_00\n",
            "start=83.2s stop=88.3s speaker_SPEAKER_01\n",
            "start=89.0s stop=91.2s speaker_SPEAKER_01\n",
            "start=92.0s stop=95.3s speaker_SPEAKER_01\n",
            "start=95.7s stop=96.0s speaker_SPEAKER_01\n",
            "start=96.3s stop=100.9s speaker_SPEAKER_00\n",
            "start=101.2s stop=104.3s speaker_SPEAKER_00\n",
            "start=104.5s stop=108.9s speaker_SPEAKER_00\n",
            "start=109.6s stop=109.6s speaker_SPEAKER_01\n",
            "start=109.6s stop=110.0s speaker_SPEAKER_00\n",
            "start=110.0s stop=110.3s speaker_SPEAKER_01\n",
            "start=110.7s stop=111.5s speaker_SPEAKER_00\n",
            "start=112.9s stop=113.9s speaker_SPEAKER_01\n",
            "start=114.3s stop=118.2s speaker_SPEAKER_01\n",
            "start=119.2s stop=120.9s speaker_SPEAKER_01\n",
            "start=121.9s stop=123.5s speaker_SPEAKER_01\n",
            "start=124.6s stop=127.2s speaker_SPEAKER_01\n",
            "start=127.7s stop=134.4s speaker_SPEAKER_00\n",
            "start=134.6s stop=144.9s speaker_SPEAKER_00\n",
            "start=146.2s stop=151.7s speaker_SPEAKER_01\n",
            "start=152.4s stop=153.9s speaker_SPEAKER_01\n",
            "start=152.4s stop=154.0s speaker_SPEAKER_00\n",
            "start=154.0s stop=154.0s speaker_SPEAKER_01\n",
            "start=154.0s stop=154.0s speaker_SPEAKER_00\n",
            "start=155.6s stop=158.7s speaker_SPEAKER_01\n",
            "start=159.8s stop=161.9s speaker_SPEAKER_01\n",
            "start=162.4s stop=163.7s speaker_SPEAKER_01\n",
            "start=164.4s stop=166.3s speaker_SPEAKER_01\n",
            "start=166.6s stop=169.0s speaker_SPEAKER_01\n",
            "start=169.7s stop=173.1s speaker_SPEAKER_01\n",
            "start=169.7s stop=170.7s speaker_SPEAKER_00\n",
            "start=173.4s stop=174.1s speaker_SPEAKER_00\n",
            "start=174.4s stop=178.1s speaker_SPEAKER_00\n",
            "start=178.3s stop=181.4s speaker_SPEAKER_00\n",
            "start=181.7s stop=184.4s speaker_SPEAKER_00\n",
            "start=184.6s stop=187.5s speaker_SPEAKER_00\n",
            "start=188.1s stop=190.1s speaker_SPEAKER_00\n",
            "start=190.8s stop=194.8s speaker_SPEAKER_00\n",
            "start=196.1s stop=196.8s speaker_SPEAKER_00\n",
            "start=197.5s stop=198.7s speaker_SPEAKER_00\n",
            "start=199.4s stop=201.8s speaker_SPEAKER_00\n",
            "start=202.4s stop=203.8s speaker_SPEAKER_00\n",
            "start=204.3s stop=206.4s speaker_SPEAKER_00\n",
            "start=207.0s stop=207.7s speaker_SPEAKER_00\n",
            "start=208.1s stop=209.8s speaker_SPEAKER_00\n",
            "start=210.8s stop=211.5s speaker_SPEAKER_00\n",
            "start=211.7s stop=217.5s speaker_SPEAKER_00\n",
            "start=218.1s stop=218.5s speaker_SPEAKER_00\n"
          ]
        }
      ],
      "source": [
        "# print the result\n",
        "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
        "    print(f\"start={turn.start:.1f}s stop={turn.end:.1f}s speaker_{speaker}\")\n",
        "# start=0.2s stop=1.5s speaker_0\n",
        "# start=1.8s stop=3.9s speaker_1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnshCwLRMfpG"
      },
      "source": [
        "### Диаризация Whisper diarisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KVx97xdfPct1",
        "outputId": "5139cc68-211b-4cd1-c4d4-66e6afabeb7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pydub\n",
        "#!pip install git+https://github.com/openai/whisper.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HPcXECUV1Vv"
      },
      "outputs": [],
      "source": [
        "import torchaudio\n",
        "\n",
        "# Конвертация MP3 в WAV\n",
        "waveform, sample_rate = torchaudio.load(\"audio_7.mp3\")\n",
        "torchaudio.save(\"audio_7.wav\", waveform, sample_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWx-mddnLti4"
      },
      "source": [
        "https://github.com/MahmoudAshraf97/whisper-diarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wv_uuy0rPQRO"
      },
      "outputs": [],
      "source": [
        "import whisper\n",
        "from pyannote.audio import Pipeline\n",
        "import torch\n",
        "from pydub import AudioSegment\n",
        "from typing import List, Dict, Tuple\n",
        "import numpy as np\n",
        "#!pip install faster-whisper\n",
        "#from faster_whisper import WhisperModel\n",
        "\n",
        "class SpeechDiarizer:\n",
        "    def __init__(self, whisper_model: str = \"medium\", hf_token: str = None):\n",
        "        \"\"\"\n",
        "        Инициализация моделей для транскрибации и диаризации\n",
        "\n",
        "        :param whisper_model: Модель Whisper (tiny, base, small, medium, large)\n",
        "        :param hf_token: Токен для Hugging Face (необходим для pyannote.audio)\n",
        "        \"\"\"\n",
        "        # Загрузка модели Whisper\n",
        "\n",
        "        # model = WhisperModel(\"medium\", compute_type=\"int8\")  # int8/fp16\n",
        "        # segments, _ = model.transcribe(\"audio_2.mp3\")\n",
        "\n",
        "        self.whisper_model = whisper.load_model(whisper_model)\n",
        "\n",
        "        # Загрузка модели диаризации (требуется токен Hugging Face)\n",
        "        if hf_token is None:\n",
        "            raise ValueError(\"Необходим токен Hugging Face для использования pyannote.audio\")\n",
        "\n",
        "        self.diarization_pipeline = Pipeline.from_pretrained(\n",
        "            \"pyannote/speaker-diarization-3.1\",\n",
        "            use_auth_token=hf_token\n",
        "        ).to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
        "\n",
        "    def transcribe_and_diarize(self, audio_path: str) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Транскрибирует аудио и выполняет диаризацию\n",
        "\n",
        "        :param audio_path: Путь к аудиофайлу\n",
        "        :return: Список сегментов с текстом и меткой диктора\n",
        "        \"\"\"\n",
        "        # 1. Транскрибация с Whisper\n",
        "        result = self.whisper_model.transcribe(audio_path)\n",
        "        segments = result[\"segments\"]\n",
        "\n",
        "        # 2. Диаризация с pyannote.audio\n",
        "        diarization = self.diarization_pipeline(audio_path)\n",
        "\n",
        "        # 3. Сопоставление сегментов транскрибации с диаризацией\n",
        "        aligned_segments = self._align_segments(segments, diarization)\n",
        "\n",
        "        return aligned_segments\n",
        "\n",
        "    def _align_segments(self,\n",
        "                       whisper_segments: List[Dict],\n",
        "                       diarization) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Сопоставляет сегменты транскрибации с результатами диаризации\n",
        "\n",
        "        :param whisper_segments: Сегменты из Whisper\n",
        "        :param diarization: Результат диаризации\n",
        "        :return: Объединенные сегменты с информацией о дикторе\n",
        "        \"\"\"\n",
        "        aligned = []\n",
        "\n",
        "        # Преобразуем диаризацию в список для удобства\n",
        "        diarization_segments = []\n",
        "        for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
        "            diarization_segments.append({\n",
        "                \"start\": turn.start,\n",
        "                \"end\": turn.end,\n",
        "                \"speaker\": speaker\n",
        "            })\n",
        "\n",
        "        # Для каждого сегмента Whisper находим соответствующего диктора\n",
        "        for ws in whisper_segments:\n",
        "            ws_start = ws[\"start\"]\n",
        "            ws_end = ws[\"end\"]\n",
        "\n",
        "            # Находим все сегменты диаризации, которые пересекаются с текущим сегментом Whisper\n",
        "            overlapping_speakers = []\n",
        "            for ds in diarization_segments:\n",
        "                if not (ds[\"end\"] < ws_start or ds[\"start\"] > ws_end):\n",
        "                    # Рассчитываем продолжительность пересечения\n",
        "                    overlap_start = max(ws_start, ds[\"start\"])\n",
        "                    overlap_end = min(ws_end, ds[\"end\"])\n",
        "                    overlap_duration = overlap_end - overlap_start\n",
        "\n",
        "                    overlapping_speakers.append({\n",
        "                        \"speaker\": ds[\"speaker\"],\n",
        "                        \"duration\": overlap_duration\n",
        "                    })\n",
        "\n",
        "            # Определяем основного диктора для сегмента\n",
        "            if overlapping_speakers:\n",
        "                # Выбираем диктора с наибольшим временем пересечения\n",
        "                main_speaker = max(overlapping_speakers, key=lambda x: x[\"duration\"])[\"speaker\"]\n",
        "            else:\n",
        "                main_speaker = \"UNKNOWN\"\n",
        "\n",
        "            aligned.append({\n",
        "                \"start\": ws_start,\n",
        "                \"end\": ws_end,\n",
        "                \"text\": ws[\"text\"],\n",
        "                \"speaker\": main_speaker\n",
        "            })\n",
        "\n",
        "        return aligned\n",
        "\n",
        "    def format_output(self, segments: List[Dict]) -> str:\n",
        "        \"\"\"\n",
        "        Форматирует результат в читаемый текст с разметкой дикторов\n",
        "\n",
        "        :param segments: Сегменты с информацией о дикторах\n",
        "        :return: Отформатированная строка\n",
        "        \"\"\"\n",
        "        output = []\n",
        "        current_speaker = None\n",
        "\n",
        "        for seg in segments:\n",
        "            if seg[\"speaker\"] != current_speaker:\n",
        "                output.append(f\"\\n[{seg['speaker']}]\")\n",
        "                current_speaker = seg[\"speaker\"]\n",
        "            output.append(seg[\"text\"])\n",
        "\n",
        "        return \" \".join(output).strip()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07iCuN54QZis",
        "outputId": "216b5388-9d8c-4f1b-a933-f0fc7330b7d4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.11/dist-packages/pyannote/audio/models/blocks/pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)\n",
            "  std = sequences.std(dim=-1, correction=1)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[SPEAKER_00]  Здравствуйте! Благодарим вас за звонок в нашу компанию. Пожалуйста, наберите внутренний номер сотрудника в Тоновом режиме. Если вы хотите отправить факс, нажмите 0 или дождитесь ответа оператора. \n",
            "[SPEAKER_01]  Компания ***. Добрый день. \n",
            "[SPEAKER_00]  Добрый день. Меня зовут Елена. Компания ***. Скажите, кто у вас занимается сайтом компании? \n",
            "[SPEAKER_01]  В общем, можно поговорить? \n",
            "[SPEAKER_00]  Скажите, пожалуйста, как вас зовут? \n",
            "[SPEAKER_01]  Елена. \n",
            "[SPEAKER_00]  Очень приятно. Елена, наша компания увеличивает переток клиентов из интернета. Мы предлагаем вам комплексное продвижение вашего сайта. Сгорайте выводов топ-10.  Все наши клиенты в 4-6 раз увеличили количество звонков и заявок с сайта, причем многие сократили свои расходы на рекламу до 50%.  Также у нас есть вариант продвижения, при котором вы платите только за результат. Это продвижение с оплатой за действие или с оплатой за тратик.  Елена, скажите, какой у вас примерный бюджет на рекламу? \n",
            "[SPEAKER_01]  Пока сложно сказать. Вы отправите предложение на Эликатеронку? \n",
            "[SPEAKER_00]  Да, конечно, Елена. Я вышлю вам наше общее коммерческое предложение, пока наш специалист может пообщаться с вами, подробнее рассказать о выгоде сотрудничества с нами.  Скажите, например, среду вам будет удобно в первой половине дня? \n",
            "[SPEAKER_01]  Во второй. \n",
            "[SPEAKER_00]  Хорошо, во второй половине дня. Елена, скажите, пожалуйста, ваше отчество? \n",
            "[SPEAKER_01]  Николаевна. \n",
            "[SPEAKER_00]  Елена Николаевна, есть ли прямой номер телефона, по которому можно с вами связаться или звонить на этот же? \n",
            "[SPEAKER_01]  На этот же. \n",
            "[SPEAKER_00]  Назовите адрес электронной почты для того, чтобы я могла отправить вам коммерческое предложение. \n",
            "[SPEAKER_01]  Собачка-мэл.ру \n",
            "[SPEAKER_00]  Скажите, пожалуйста, вы уже продвигаете сайт с кем-то?  Пока нет.  Назовите название вашего сайта.  ***.про  Скажите, пожалуйста, регион продвижения?  Требовского мэйс.  Хорошо. Елена Николаевна, тогда в среду, 28 декабря, наш специалист будет с вами во второй половине дня.  А пока отправлю вам информационный материал. Всего доброго, до свидания. \n",
            "[SPEAKER_01]  До свидания.\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Укажите ваш токен Hugging Face\n",
        "    HF_TOKEN = \"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\"\n",
        "\n",
        "    # Инициализация диаризатора\n",
        "    diarizer = SpeechDiarizer(whisper_model=\"medium\", hf_token=HF_TOKEN)\n",
        "\n",
        "    # Обработка аудиофайла\n",
        "    audio_file = \"audio_6.wav\"\n",
        "    result = diarizer.transcribe_and_diarize(audio_file)\n",
        "\n",
        "    # Вывод результатов\n",
        "    formatted_output = diarizer.format_output(result)\n",
        "    print(formatted_output)\n",
        "\n",
        "    # Можно также сохранить результаты в файл\n",
        "    with open(\"транскрипция_с_дикторами.txt\", \"w\") as f:\n",
        "        f.write(formatted_output)\n",
        "\n",
        "# время выполнения кода ~12 мин 30 сек (audio_1)\n",
        "# время выполнения кода ~18 мин 24 сек (audio_2)\n",
        "# время выполнения кода ~13 мин 59 сек (audio_3)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Z6NPGe-IHXY2"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "062e4a03a91e4afd921e6797f47e7eec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_17aa96183fb540d7bfd31fadb962de4f",
              "IPY_MODEL_8ba35415ddd44cfa838b5af9629b6bf4",
              "IPY_MODEL_85553ced5d3e488eb1eeb649cd99594a"
            ],
            "layout": "IPY_MODEL_86a0af961ded4990bdc25d201537734c"
          }
        },
        "06b17a36df034c9eaeab8a42574cf773": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b875ba0fd634619b8427b1cef31e0e8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17aa96183fb540d7bfd31fadb962de4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccf450aafc32413192a48963af5d16b3",
            "placeholder": "​",
            "style": "IPY_MODEL_b9a6dba9fb3640a081114f55e4e3790c",
            "value": "config.yaml: 100%"
          }
        },
        "180d77b32d3f4bf08c07b2d36cbe5d9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "248ddd7db65141a9a1efbaa9a9ddeef3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84b2d413b872446285ab01250474f502",
            "placeholder": "​",
            "style": "IPY_MODEL_82301003a35e42189b3660f1d6c753ef",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "248e22efa80c493ca3c2d29fafc8a961": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24d9e14ff6af402f9239007294c4e46e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35f61379fce949e1b84038b295d5e137",
            "placeholder": "​",
            "style": "IPY_MODEL_bd649642bd684207be372bd733595113",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "25bc6a5b2f8e4b26b291570834186916": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59c4dd37c2d94c4f9260f78eb5fb99fc",
            "placeholder": "​",
            "style": "IPY_MODEL_9d2a27323a52452d8ea00ba3bec0d8a4",
            "value": "config.yaml: 100%"
          }
        },
        "2959c2ee84174193950a989b6ff59d70": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c22cd0359611478ab2d3ba1ede548201",
            "max": 26645418,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d89288125b2942bb8463ff608aa3b5f1",
            "value": 26645418
          }
        },
        "29d739daf2174af2be322a6397bfb77c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "35f61379fce949e1b84038b295d5e137": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4075c13bd969492daec3fca92d66ce11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6e6b53f092f46f9bae9f7763589bd1b",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_90dff87964e34563a1d7d885cbe5691f",
            "value": 469
          }
        },
        "43d3a98bf3fc4d828a745939e333bd15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e9de951956a4924ac717c2d33b3580b",
            "placeholder": "​",
            "style": "IPY_MODEL_87a027d9cded44ba92bb1e5dde014c5e",
            "value": " 5.91M/5.91M [00:00&lt;00:00, 37.6MB/s]"
          }
        },
        "45259112edde4f6a9a47559d91bcd531": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4da97bcae597421aa6bbbb7e49bd07ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f42f1bf6811d49f58103615672ad4f1c",
            "max": 5905440,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_06b17a36df034c9eaeab8a42574cf773",
            "value": 5905440
          }
        },
        "4e9de951956a4924ac717c2d33b3580b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5186c74dc1aa47209a24a6c63864cdec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59c4dd37c2d94c4f9260f78eb5fb99fc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cd9bab718ef4f999e5d4248d7dcb212": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b693180dff7a441fac5aad545ef4f53e",
            "placeholder": "​",
            "style": "IPY_MODEL_248e22efa80c493ca3c2d29fafc8a961",
            "value": " 399/399 [00:00&lt;00:00, 22.8kB/s]"
          }
        },
        "6d5912a4cc8740c887fca68af713874a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_24d9e14ff6af402f9239007294c4e46e",
              "IPY_MODEL_2959c2ee84174193950a989b6ff59d70",
              "IPY_MODEL_6fe60b7ad2a94890b1ff8ba223e9148d"
            ],
            "layout": "IPY_MODEL_0b875ba0fd634619b8427b1cef31e0e8"
          }
        },
        "6e51b7d0bf0d4b5da21ba0d51be02a95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_25bc6a5b2f8e4b26b291570834186916",
              "IPY_MODEL_4075c13bd969492daec3fca92d66ce11",
              "IPY_MODEL_71786e70a4a640f28e47505966941716"
            ],
            "layout": "IPY_MODEL_c9a0658e8a8343d880cb883d3af9d5a2"
          }
        },
        "6fe60b7ad2a94890b1ff8ba223e9148d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91fd9118c2ed4d8eb3c8345eb45aac01",
            "placeholder": "​",
            "style": "IPY_MODEL_e2308566350a4bbc9148db5957220fdc",
            "value": " 26.6M/26.6M [00:00&lt;00:00, 55.4MB/s]"
          }
        },
        "71786e70a4a640f28e47505966941716": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5186c74dc1aa47209a24a6c63864cdec",
            "placeholder": "​",
            "style": "IPY_MODEL_eafdb00f20684e1f859fded6baab015d",
            "value": " 469/469 [00:00&lt;00:00, 39.5kB/s]"
          }
        },
        "82301003a35e42189b3660f1d6c753ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84b2d413b872446285ab01250474f502": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85553ced5d3e488eb1eeb649cd99594a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df282dda1fcc4364b3349c68cb3288ad",
            "placeholder": "​",
            "style": "IPY_MODEL_180d77b32d3f4bf08c07b2d36cbe5d9f",
            "value": " 221/221 [00:00&lt;00:00, 19.0kB/s]"
          }
        },
        "86a0af961ded4990bdc25d201537734c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87a027d9cded44ba92bb1e5dde014c5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ab9a25471c742d69ad8b7b0af94844c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8e0fcbfec99640829d2f16984ebcad66",
              "IPY_MODEL_df90995d606d48a39f401b3899cbb3d3",
              "IPY_MODEL_5cd9bab718ef4f999e5d4248d7dcb212"
            ],
            "layout": "IPY_MODEL_c6cbb1d2168b4558908be22374241fc5"
          }
        },
        "8ba35415ddd44cfa838b5af9629b6bf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abd706b7527a4266a4662137405ad53d",
            "max": 221,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45259112edde4f6a9a47559d91bcd531",
            "value": 221
          }
        },
        "8e0fcbfec99640829d2f16984ebcad66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df3d827da1c044ed85eb5f7067206b1d",
            "placeholder": "​",
            "style": "IPY_MODEL_e772304c69e24c6fad7f47c239ef04ea",
            "value": "config.yaml: 100%"
          }
        },
        "90dff87964e34563a1d7d885cbe5691f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "91fd9118c2ed4d8eb3c8345eb45aac01": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bbf12000f744c699e96c06d76db4549": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_248ddd7db65141a9a1efbaa9a9ddeef3",
              "IPY_MODEL_4da97bcae597421aa6bbbb7e49bd07ea",
              "IPY_MODEL_43d3a98bf3fc4d828a745939e333bd15"
            ],
            "layout": "IPY_MODEL_f2a60e781b4e401e8dc56ee8ea44cf43"
          }
        },
        "9d2a27323a52452d8ea00ba3bec0d8a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6e6b53f092f46f9bae9f7763589bd1b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abd706b7527a4266a4662137405ad53d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b693180dff7a441fac5aad545ef4f53e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9a6dba9fb3640a081114f55e4e3790c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd649642bd684207be372bd733595113": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c22cd0359611478ab2d3ba1ede548201": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6cbb1d2168b4558908be22374241fc5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6fbb1419e784ab889337a4caaf87c2d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9a0658e8a8343d880cb883d3af9d5a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccf450aafc32413192a48963af5d16b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d89288125b2942bb8463ff608aa3b5f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "df282dda1fcc4364b3349c68cb3288ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df3d827da1c044ed85eb5f7067206b1d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df90995d606d48a39f401b3899cbb3d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6fbb1419e784ab889337a4caaf87c2d",
            "max": 399,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_29d739daf2174af2be322a6397bfb77c",
            "value": 399
          }
        },
        "e2308566350a4bbc9148db5957220fdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e772304c69e24c6fad7f47c239ef04ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eafdb00f20684e1f859fded6baab015d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2a60e781b4e401e8dc56ee8ea44cf43": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f42f1bf6811d49f58103615672ad4f1c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
